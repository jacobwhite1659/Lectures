{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 6 \n",
    "* Combinatorics\n",
    "* Bayes' Theorem and Applications\n",
    "* Exploratory Data Analysis\n",
    "* Hypothesis Testing\n",
    "* Bootstrap Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are some of the theorems and corollaries that we have learned so far:\n",
    "\n",
    "* $\\forall E\\in\\mathcal{F}, 0 \\leq P(E)\\leq 1$\n",
    "* $P(\\Omega)=1$ and $P(\\emptyset) = 0 $\n",
    "* $P(A^c) = P(\\overline{A}) = 1 - P(A)$\n",
    "* If $A\\subset B$, then $P(A)\\leq P(B)$\n",
    "* **DeMorgan's Law 1**: $\\overline{A\\cap B} = \\overline{A}\\cup\\overline{B}$  \n",
    "* **DeMorgan's Law 2**: $\\overline{A\\cup B} = \\overline{A}\\cap\\overline{B}$\n",
    "* $P(A\\cap B) = P(A) + P(B) - P(A\\cup B)$\n",
    "* If $A$ and $B$ are M.E. then $A\\cap B=\\emptyset \\Rightarrow P(A\\cap B) = 0$\n",
    "* **Conditional Probability**: $P(A|B) = \\frac{P(A\\cap B)}{P(B)}$, for $P(B)>0$\n",
    "* **Chain Rules**: $P(A\\cap B) = P(A|B)P(B)$ and $P(A\\cap B) = P(B|A)P(A)$\n",
    "* **Multiplication Rule**: $P(\\bigcap_{i=1}^n A_i) = P(A_1)P(A_2|A_1)P(A_3|A_1\\cap A_2)\\dots P\\left(A_n|A_1\\cap\\dots \\cap A_{n-1}\\right)$\n",
    "* **Total Probability**: if a set of events $\\{C_i\\}_{i=1}^n$ are partitions of the sample space $\\Omega$, then $P(A) = \\sum_{i=1}^n P(A|C_i)P(C_i)$\n",
    "* **Statistical Independence:** two events $A, B\\in\\mathcal{F}$ are statistical independent (s.i.) if and only if (iff) $P(A\\cap B)=P(A)P(B)$\n",
    "* If $A$ is statistically independent of $B$, then $B$ is statistically independent of $A$.\n",
    "* If $A, B\\in\\mathcal{F}$ are s.i., then $A$ and $\\bar{B}$ are s.i., $\\bar{A}$ and $B$ are s.i., and $\\bar{A}$ and $\\bar{B}$ are s.i..\n",
    "* **Conditional Independence:** Given an event $C$, the events $A$ and $B$ are said to be conditionally independent if $P(A\\cap B|C) = P(A|C)P(B|C)$\n",
    "* Conditionally independent events are not necessary statistically independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library API for [itertools](https://docs.python.org/3/library/itertools.html).\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinatorics\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "A **combined experiment** is one in which the outcome is a tuple that takes one outcome from each of a sequence of subexperiments.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <b>Cartesian Product</b>\n",
    "    \n",
    "The **cartesian product** of two sets $A$ and $B$ is denoted $A \\times B$ and is defined by \n",
    "\n",
    "$$ A \\times B = \\{ (a,b) | a \\in A \\mbox{ and } b \\in B\\}$$\n",
    "\n",
    "That is, it is the set of all two-tuples with the first element from set $A$ and the second element from set $B$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sampling with Replacement and with Ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Sampling with replacement and with ordering</b>\n",
    "    \n",
    "Consider choosing $k$ values from a set of $n$ values. The result is a $k$-tuple: $(x_1, x_2, \\ldots, x_k)$, \n",
    "where $x_i \\in A, \\forall i=1,2,\\ldots, k$. \n",
    "\n",
    "Thus, this is a combined experiment with $|S_1|=|S_2|=\\ldots=|S_k|=|A|\\equiv n$.\\\\\n",
    "\n",
    "Therefore the number of distinct ordered $k$-tuple outcomes is $n^k$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sampling without Replacement and with Ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Sampling without replacement and with ordering ($k$-permutations)</b>\n",
    "    \n",
    "In general, the number of ways to choose $k$ items from $n$ items **without replacement** and **with ordering** is\n",
    "$$ n \\times (n-1) \\times \\ldots \\times (n-k+1) = \\frac{n!}{(n-k)!}$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=blue>Example 1:</font> Consider the combined experiment of flipping a fair coin 20 times and counting the number of heads. How many ways are there to observe a count of 2 heads in 20 coin flips?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PYTHON technique** To compute the factorial of an integer in Python, you can use the ```scipy``` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in counting the number of ways that 2 Heads can occur in 20 flips, (7,14) represents the same thing as (14,7). \n",
    "\n",
    "So, if we determine the number of **ordered** ways to choose 2 unique values out of 20, we have **overcounted** by a factor of 2.\n",
    "\n",
    "Thus, the correct number of outcomes in $H_2$ is\n",
    "$$ \\left|H_2 \\right| = \\frac{20 \\cdot 19}{2} = 190 $$ \n",
    "\n",
    "Now, let's try to count $|H_3|$. We know the number of ways to choose 3 **ordered** values from 20 without replacement is\n",
    "$$\\frac{20!}{(20-3)!} = 20 \\cdot 19 \\cdot 18$$\n",
    "\n",
    "But how many repeats are there if we want to know the number of unordered sets? Let's consider how many ways we can arrange (1,2,3):\n",
    "\n",
    "(1,2,3)\n",
    "(1,3,2)\n",
    "(2,1,3)\n",
    "(2,3,1)\n",
    "(3,1,2)\n",
    "(3,2,1)\n",
    "\n",
    "So, there are 6.\n",
    "\n",
    "Note that the number of ways to order 3 things is the same as the number of order ways to choose 3 items from a set of 3.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <b>Permutations</b>\n",
    "    \n",
    "The number of *permutations* of $k$ objects is the number of orderings of those $k$ objects, and can be calculated as\n",
    "$$ k \\times (k-1) \\times (k-2) \\times \\ldots \\times 2 \\times 1 \\\\ = k! $$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sampling without Replacement and without Ordering\n",
    "\n",
    "Finally, we are ready to determine $|H_3|$, which is $20 \\times 19 \\times 18$ divided by the number of orderings of 3 items, which is $3!=6$, so\n",
    "\n",
    "\\begin{align*}\n",
    "\\left|H_3\\right| &= \\frac{20!}{(20-3)!}\\frac{1}{3!} \\\\\n",
    "&=\\frac{20 \\times 19 \\times 18}{6} \\\\\n",
    "&= 1140\n",
    "\\end{align*}\n",
    "\n",
    "Moreover, the formula for general $H_k$ follows directly.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <b>Sampling without Replacement and without Ordering (Combinations)</b>\n",
    "    \n",
    "The number of ways to choose $k$ items from a set of $n$ items **without replacement** and **without ordering** is\n",
    "$$  \\frac{n!}{(n-k)!k!} $$\n",
    "\n",
    "The value of the equation can also be expressed as\n",
    "$$ \\binom{n}{k} = C^{n}_{k} $$\n",
    "and is know as the **binomial coefficient**.\n",
    "</div>\n",
    "\n",
    "**PYTHON technique** To determine $\\binom{n}{k}$ in Python, you can also use the ```scipy``` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the probability of any event $H_k \\subset \\Omega$ is \n",
    "\n",
    "$$ P(H_k) = \\frac{|H_k|}{|\\Omega|} = \\frac{\\binom{20}{k}}{2^{20}}$$\n",
    "\n",
    "Let's put it all together and compare with our simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "num_sims=10_000\n",
    "flips=20\n",
    "threshold=6\n",
    "\n",
    "# Conducting experiment\n",
    "\n",
    "\n",
    "\n",
    "# Analytical Probability\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,5))\n",
    "\n",
    "# Counting - Observed Relative Frequencies\n",
    "\n",
    "plt.xlabel('Number of Heads')\n",
    "plt.ylabel('Relative Frequency')\n",
    "\n",
    "\n",
    "# Analytical probability\n",
    "\n",
    "plt.xlabel('Number of Heads')\n",
    "plt.ylabel('Analytical Probability')\n",
    "\n",
    "\n",
    "# Relative Frequencies vs Analytical Probability\n",
    "\n",
    "plt.xlabel('Number of Heads')\n",
    "plt.ylabel('Relative Frequency vs Analytical Probability')\n",
    "plt.show()\n",
    "\n",
    "print(\"Flip | Relative Freq. | Analytic Probability\")\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sampling with Replacement and without Ordering\n",
    "\n",
    "Suppose that we want to sample from the set $A=\\{a_1,a_2,\\dots,a_n\\}$ $k$ times such that repetition is allowed and ordering does not matter. For example, if $A=\\{1,2,3,4,5,6\\}$ is the sample space of rolling a 6-sided fair die and $k=2$, then there are 21 differet ways of doing this\n",
    "\n",
    "\\begin{equation*}\n",
    "\\{(1,1), (1,2), (1,3), (1,4), (1,5), (1,6), (2,2), (2,3), (2,4), (2,5), (2,6), (3,3), (3,4), (3,5), (3,6), (4,4), (4,5), (4,6), (5,5), (5,6), (6,6)\\}\n",
    "\\end{equation*}\n",
    "\n",
    "* How can we get the number 21 without actually listing all the possibilities? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to think about this is to note that any of the pairs in the above list can be represented by the number of 1's, 2's, 3's, 4's, 5's and 6's it contains. That is, if $x_i$ is the number of face $i$, we can equivalently represent each pair by a vector $(x_1,x_2,x_3,x_4,x_5,x_6)$, for example,\n",
    "\n",
    "\\begin{align*}\n",
    "(1,5) &\\rightarrow (x_1,x_2,x_3,x_4,x_5,x_6) = (1,0,0,0,1,0)\\\\\n",
    "(2,2) &\\rightarrow (x_1,x_2,x_3,x_4,x_5,x_6) = (0,2,0,0,0,0)\\\\\n",
    "(3,4) &\\rightarrow (x_1,x_2,x_3,x_4,x_5,x_6) = (0,0,1,1,0,0)\\\\\n",
    "(5,5) &\\rightarrow (x_1,x_2,x_3,x_4,x_5,x_6) = (0,0,0,0,2,0)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here $x_i \\geq 0$ are integers and $x_1+x_2+x_3+x_4+x_5+x_6 = k = 2$. Thus, we can claim that the number of ways we can sample two elements from the set $A=\\{1,2,3,4,5,6\\}$ such that ordering does not matter and repetition is allowed is the same as solutions to the following equation\n",
    "\n",
    "$$x_1+x_2+x_3+x_4+x_5+x_6 = 2\\text{, where } x_i\\in\\{0,1,2\\}$$\n",
    "\n",
    "This is an interesting observation and in fact using the same argument we can make the following statement for general $k$ and $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Sampling with Replacement and without Ordering (Partitions)</b>\n",
    "    \n",
    "The number of $k$-multisets of an $n$-set $A=\\{a_1,a_2,\\cdots,a_n\\}$ **with replacement** and **without ordering** are binomial coefficients of the form:\n",
    "\n",
    "$$\\binom{n + k - 1}{k} = \\binom{k + n - 1}{n-1}$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus Material:** https://www.youtube.com/watch?v=UTCScjoPymA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=blue>Example 2:</font> What is the probability of a roll of 11 when rolling 2 fair 6-sided dice?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Bayes' Theorem (sometimes called Bayes' Rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider two events $A$ and $B$, by the **chain rule** equations we know that: \n",
    "\n",
    "$$P(A\\cap B) = P(A|B)P(B)$$\n",
    "and\n",
    "$$P(B\\cap A) = P(B|A) P(A)$$\n",
    "\n",
    "Note that \n",
    "\n",
    "\\begin{align*}\n",
    "P(A\\cap B) &= P(B\\cap A)\\\\\n",
    "\\iff P(A|B)P(B) &= P(B|A) P(A)\\\\\n",
    "\\iff P(A|B) &= \\frac{P(B|A) P(A)}{P(B)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "  <strong>Bayes's Theorem</strong>\n",
    "    \n",
    "If the set of events $\\{A_i\\}_{i=1}^n$ partitions the sample space $\\Omega$, and assuming $P(A_i)>0$, for all $i$. Then, for any event $B$ such that $P(B)>0$, we have\n",
    "\n",
    "\\begin{align*}\n",
    "P(A_i|B) &= \\frac{P(B|A_i)P(A_i)}{P(B)}\n",
    "\\end{align*}\n",
    "\n",
    "where $P(B)$ can be computed using the Law of Total Probability,\n",
    "  \n",
    "\\begin{align*}\n",
    "P(B) &= P(B|A_1)P(A_1) + \\cdots +P(B|A_n)P(A_n)\n",
    "\\end{align*}\n",
    "\n",
    "</div>\n",
    "\n",
    "* **Add that to the set of formulas!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=blue>Example 3:</font> Consider the experiment where we select between a fair 6-sided die and a fair 12-sided die at random and flip it once. What is the probability that the die selected was the 12-sided die if face on top was 5?**\n",
    "\n",
    "<!-- \n",
    "Let $S$ be the event that the fair 6-sided die was selected, $T$ the event that the fair 12-sided die was selected, and $D_i$ the event that the face $i$ was rolled.\n",
    "\n",
    "$$P(T|D_5) = \\frac{P(T\\cap D_5)}{P(D_5)} = \\frac{P(D_5|T)P(T)}{P(D_5)}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$P(D_5) = P(D_5|S)P(S) + P(D_5|T)P(T) = \\frac{1}{6}\\times\\frac{1}{2} + \\frac{1}{12}\\times\\frac{1}{2} = 0.125$$\n",
    "\n",
    "Putting it together,\n",
    "\n",
    "$$P(T|D_5) = \\frac{P(D_5|T)P(T)}{P(D_5|S)P(S) + P(D_5|T)P(T)} = \\frac{\\frac{1}{12}\\times\\frac{1}{2}}{\\frac{1}{6}\\times\\frac{1}{2} + \\frac{1}{12}\\times\\frac{1}{2}}=\\frac{1}{3}$$ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that die is 12-sided if observed result is 5 is \n"
     ]
    }
   ],
   "source": [
    "num_sims=100_000\n",
    "dice = ['6-sided','12-sided']\n",
    "\n",
    "## COMPLETE IN CLASS\n",
    "\n",
    "print('Probability that die is 12-sided if observed result is 5 is ',\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bayes's rule is an extremely useful theorem and is often used for **statistical inference**.\n",
    "\n",
    "There are a number of *causes* that may result in a certain *effect*. We observe the effect, and we wish to infer the cause.\n",
    "\n",
    "* The events $A_1, A_2,\\dots,A_n$ can be characterized as a set of possible causes, and\n",
    "* The event $B$ represents the effect\n",
    "\n",
    "The probability $P(B|A_i)$ computes the probability that the effect $B$ will be observed when the cause $A_i$ is present. This amounts to a probabilistic model for a cause-effect relationship.\n",
    "\n",
    "Given that the effect $B$ has occurred, we want to evaluate the probability $P(B|A_i)$ that the cause $A_i$ is present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We refer to $P(A_i|B)$ as the **<font color=green>posterior probability</font>** of event $A_i$ given the information\n",
    "\n",
    "* We refer to $P(A_i)$ as the **<font color=orange>prior probability</font>**\n",
    "\n",
    "* We refer to $P(B|A_i)$ as the **<font color=blue>likelihood</font>**\n",
    "\n",
    "* We refer to $P(B)$ as the **<font color=brown>evidence/effect probability</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=blue>Example 4:</font> A test for a certain rare disease is assumed to be correct 95% of the time: if a person has the disease, the test results are positive with probability 0.95, and if the person does not have the disease, the test results are negative with probability 0.95. A random person drawn from a certain *population* has probability 0.001 of having the disease. Given that the person just tested positive, what is the probability that the person has the disease?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Let $A$ be the event that the person has the disease, $B$ the event that the test results are positive. We are given that $P(B|A) = 0.95$ and $P(A) = 0.001$. We want to compute $P(A|B)$.\n",
    "\n",
    "\\begin{align*}\n",
    "P(A|B) &= \\frac{P(B|A)P(A)}{P(B)}\\\\\n",
    "&= \\frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|\\overline{A})P(\\overline{A})}\\\\\n",
    "&= \\frac{0.95 \\times 0.001}{0.95\\times 0.001 + 0.05\\times 0.999}\\\\\n",
    "&\\approx 0.0187\n",
    "\\end{align*} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Statistics vs Classic Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "The Bayes' theorem is an *extremely* useful result, formulated by Thomas Bayes in the 18th century and later published by Richard Price.\n",
    "\n",
    "This result originated the term **Bayesian statistics** or **Bayesian inference**, giving a different interpretation of probability when compared to **classic statistics** or **Frequentist inference**.\n",
    "\n",
    "* **Frequentist statistics**: refers to the field of statistics that draws conclusions from data by computing relative frequency of events in the data.\n",
    "\n",
    "* **Bayesian statistics**: refers to the field of statistics that draws conclusions from data by testing out the hypothesis and computing their observed probability from data.\n",
    "\n",
    "In **inference**, Bayes' rule makes use of a **prior** which is an assumption made about some underlying phenomenon. Bayes' equation makes use of this prior probability to compute the probability of such cause given some observational data.\n",
    "\n",
    "Whereas in classical inference, no assumption are made about the underlying nature of the system that generated the observational data. It's inference is purely based on how the frequency of outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "![ThomasBayes](https://upload.wikimedia.org/wikipedia/commons/d/d4/Thomas_Bayes.gif)\n",
    "Thomas Bayes (1701-1761), [Wikipedia page](https://en.wikipedia.org/wiki/Thomas_Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which statistical approach should I use to draw conclusions from my data?** We will see that it *depends* on\n",
    "1. the problem\n",
    "2. the actual quantity (and quality) of the observational data that you have\n",
    "3. whether or not you have prior beliefs\n",
    "4. other factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('https://imgs.xkcd.com/comics/frequentists_vs_bayesians_2x.png',width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=blue>Example 5:</font> Suppose that I flipped a coin 5 times and observe the event $E=\\{H,H,H,H,H\\}$. Without telling you anything else, what is the probability of heads? What would your answer be?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **hidden state** of this problem is: what coin was used for this experiment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Frequentist statistics: $P(H) = \\frac{|H|}{|E|} = \\frac{5}{5} = 1$. \n",
    "\n",
    "It does not use any prior beliefs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bayesian statistics: you start by assuming that chances are e.g. I'm flipping a fair coin - this is your prior belief, that the coin is fair, then $P(H|\\text{fair})=\\frac{1}{2}$, furthermore you also compute a probability for that hypothesis:\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\text{fair}| E) &= \\frac{P(E|\\text{fair})P(\\text{fair})}{P(E)}\\\\\n",
    "&= \\frac{P(E|\\text{fair})P(\\text{fair})}{P(E|\\text{fair})P(\\text{fair})+P(E|\\text{unfair})P(\\text{unfair})}\\\\\n",
    "&= \\frac{\\left(\\frac{1}{2}\\right)^5\\times\\frac{1}{2}}{\\left(\\frac{1}{2}\\right)^5\\times\\frac{1}{2}+(1)^5\\times\\frac{1}{2}}, \\text{ assuming you believe it to be 50/50 between fair and 2-headed}\\\\\n",
    "&\\approx 0.0303\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you thought I had 2 fair coin and 1 2-headed, then the probability for fair coin is $\\frac{2}{3}$ and probability for 2-headed was $\\frac{1}{3}$. With this, the probability of the hypothesis/cause \"coin is fair\" is:\n",
    "\n",
    "$$P(\\text{fair}| E) = \\frac{\\left(\\frac{1}{2}\\right)^5\\times\\frac{2}{3}}{\\left(\\frac{1}{2}\\right)^5\\times\\frac{2}{3}+(1)^5\\times\\frac{1}{3}} \\approx 0.0588$$\n",
    "\n",
    "Note that a **stronger (prior) belief** influenced the probability of your **hypothesis**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is where the (healthy) \"rivalry\" between Frequentist vs Bayesian emerges:**\n",
    "\n",
    "* Frequentists say that we should never make assumptions (prior beliefs) because they will change the probability of the hypothesis. Frequestists support that the use of the observational data is the approach to take conclusions. Frequentist approach to probability is **data-driven**.\n",
    "\n",
    "* Bayesians say that in situations where we do not have enough data, it is prudent to make assumptions as the conclusions will become more \"realistic\".\n",
    "\n",
    "There are strategies to adjust the prior belief (correct its value to a *better* value) as we continue to collect more observations. We will study this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applications of Bayesian inference are endless. These are some examples:\n",
    "\n",
    "1. Decision theory, e.g. communication system (example next lecture)\n",
    "\n",
    "2. Bioinformatics and healthcare, e.g. building a risk model from genetic profiles\n",
    "\n",
    "3. Recommender systems, e.g. Netflix\n",
    "\n",
    "4. Stock market prediction\n",
    "\n",
    "5. Email spam filter\n",
    "\n",
    "6. Financing, e.g. banks are using Bayesian inference to determine interest rates of a loan by using a risk model\n",
    "\n",
    "8. many, many others..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A first look at the data*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Exploratory Data Analysis</b>\n",
    "    \n",
    "**Exploratory data analysis** or **EDA** is a critical first step in analyzing the data from an experiment. Here are the main reasons we use EDA:\n",
    "* detection of mistakes\n",
    "* checking of assumptions\n",
    "* preliminary selection of appropriate models\n",
    "* determining relationships among the explanatory variables, and\n",
    "* assessing the direction and rough size of relationships between explanatory and outcome variables.\n",
    "\n",
    "Loosely speaking, any method of looking at data that does not include formal statistical modeling and inference falls under the term exploratory data analysis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis is generally cross-classified in two ways. First, each method is either \n",
    "\n",
    "1. **non-graphical**, or \n",
    "2. **graphical**. \n",
    "\n",
    "And second, each method is either \n",
    "* **univariate**, or \n",
    "* **multivariate** (usually just bivariate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Types of EDA</b>\n",
    "    \n",
    "The four types of EDA are:\n",
    "* univariate non-graphical\n",
    "* multivariate non-graphical\n",
    "* univariate graphical\n",
    "* multivariate graphical\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-graphical methods generally involve calculation of **summary statistics**, while graphical methods obviously summarize the data in a diagrammatic or pictorial way. \n",
    "\n",
    "* Univariate methods look at one variable (data column) at a time, while multivariate methods look at two or more variables at a time to explore relationships. \n",
    "    * Usually our multivariate EDA will be bivariate (looking at exactly two variables), but occasionally it will involve three or more variables. \n",
    "    * *It is almost always a good idea to perform univariate EDA on each of the components of a multivariate EDA before performing the multivariate EDA.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Data\n",
    "\n",
    "The data that come from making a particular measurement on all of the subjects in a sample represent our observations for a single characteristic such as age, gender, speed at a task, or response to a stimulus. \n",
    "\n",
    "We should think of these measurements as representing a *sample distribution* of the variable, which in turn more or less represents the *population distribution* of the variable. \n",
    "\n",
    "The usual goal of univariate non-graphical EDA is to better appreciate the *sample distribution* and also to make some tentative conclusions about what population distribution(s) is/are compatible with the sample distribution. \n",
    "\n",
    "* Outlier detection is also a part of this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Population</b>\n",
    "    \n",
    "A **population** is a group of people, objects, events or observations that is being studied.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Parameters</b>\n",
    "    \n",
    "Often we are trying to assess some qualities or properties of that population. We call these **parameters**.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the population is too large to directly measure the parameters of interest, then we try to draw inferences from a subset of the population.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <b>Sample</b>\n",
    "    \n",
    "A **sample** from a population is a subset of the population that can be used to draw inferences about the parameters of interest.\n",
    "</div>\n",
    "\n",
    "* A sample is usually drawn randomly from the population.\n",
    "\n",
    "* We usually require that each member of the sample is chosen independently from other members.\n",
    "\n",
    "* Often, but not always, each member in the population is equally likely to be included in the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Statistic</b>\n",
    "    \n",
    "A **statistic** is a measurement of a quality or property on a sample that is used to assess a parameter of the whole population.\n",
    "</div>\n",
    "\n",
    "When samples are small, the statistics often provide little or no information about the parameters.\n",
    "\n",
    "* For example, consider the problem of determining whether a coin is fair or two-headed. The result of flipping a coin one time provides no useful information for determining that\n",
    "\n",
    "When samples are larger, they generally more accurately represent the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, when dealing with data, there are generally two cases that we will encounter:\n",
    "\n",
    "1. When designing an experiment, the statistician can choose the sample size to balance between being able to generate a useful statistic and the cost of taking more samples.\n",
    "\n",
    "2. Sometimes the experiment has already been carried out or is not under the control of the statistician. For instance, the statistician wants to assess something based on an existing survey or compare effects of a change in laws on a set of states. In this case, the sample size is fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Effect of 1994-2004 Federal Assault Weapon Ban\n",
    "\n",
    "In 1994, the United States Congress passed a ban on a variety of semiautomatic rifles that are sometimes referred to as \"assault weapons\". The ban was in effect for 10 years, from 1994-2004. ([State Firearm Laws](https://www.statefirearmlaws.org/resources))\n",
    "\n",
    "It might be guessed that the goal of any gun ban is to reduced gun violence. Thus it is natural to assess whether the \"assault weapon\" ban had any effect on gun violence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, the Center for Disease Control's National Center for Health Statistics tracks firearm mortality at the state level. Visualizations of firearm mortality by state, along with links to download the data are available here:\n",
    "\n",
    "https://www.cdc.gov/nchs/pressroom/sosmap/firearm_mortality/firearm.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this page does not have data prior to 2005, the data for 2005 should be similar to that before the ban because the ban was only on the **sale** of certain firearms. It would take many years for this ban to actually affect the availability of firearms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we can use two sets of data on that page to measure the effect of the \"assault weapons\" ban:\n",
    "\n",
    "* The 2005 data set represents firearm mortality after the ban had been in effect for a decade\n",
    "* The 2014 data set represents firearm mortality after the ban had been seized for a decade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have download this data and it is saved in the file called **\"firearms-combined.csv\"**.\n",
    "\n",
    "**Make sure you have the CSV file wherever you are working on this notebook!**\n",
    "\n",
    "Now let's read the data from the CSV file into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Death rates are measured per 100,000 total population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's access the sample values for columns \"RATE-2005\" and \"RATE-2014\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that I went directly to a numpy array here, instead of making a list first\n",
    "# The reason for using a numpy array is that we want to apply numpy methods for \n",
    "# computing statistics further below!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by plotting this data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common visualization is to look at a histogram of the data. Unlike the histograms we previously generated, this data takes on **real values**, not just integers. Fortunately, ```matplotlib``` has functions to do the hard work of making histograms for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some styling will help make this more legible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each bar of the histogram represents a \"bin\" of data values. In fact, the counts and bin edges are returned by the hist function. We can easily change the number of bins to provide more resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some information to make this more useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **What *inferences* might you make from this plot?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it does not make sense to make the number of bins very large compared to the data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "Summary statistics are values calculated from sample data that measure some characteristic about the data.\n",
    "\n",
    "* **What is the most common summary statistic?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **average** or **sample mean**. I **strongly** prefer the word average for the statistic computed from a set of data. \n",
    "\n",
    "We will use the word **mean** to refer to a type of average for random phenomena, when we do not have specific samples for those values. \n",
    "\n",
    "* What does the **average** or **sample mean** mean?\n",
    "\n",
    "    1. The value where most of the data \"sits\" is centered around\n",
    "    \n",
    "    2. The value that has minimum distance from every value\n",
    "    \n",
    "    3. Value most likely to occur\n",
    "    \n",
    "    4. Value that divides group into 2 sets of equal size \n",
    "\n",
    "Both ```pandas``` and ```numpy``` provide methods to calculate the average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other **summary statistics** are used to summarize a set of observations, the most common ones are:\n",
    "\n",
    "1. **Average** - the value where most of the data \"sits\" is centered around\n",
    "\n",
    "2. **Size** - number of observations in the sample data\n",
    "\n",
    "3. **Count** - number of non-empty observations in the sample data\n",
    "\n",
    "4. **Median** - the \"middle number\" of the sorted sample data values\n",
    "\n",
    "5. **Standard deviation** - is a measure of dispersion; it measures the average distance between a single observation and the average value\n",
    "\n",
    "6. **Quartiles** - the boundary values for the lowest, middle and upper quarters of the sample data\n",
    "\n",
    "7. **Inter-Quantile Range (IQR)** - where the \"middle fifty\" percent of the data is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ```pandas``` we can print a summary statistic table this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good graphical descriptor that displays a few of these summary statistics is the **boxplot** or **whisker plot**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![boxplot](https://www.simplypsychology.org/boxplot.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the ```matplotlib``` to display a boxplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can use built-in ```pandas``` graphic visualizations directly on dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **What *inferences* might you make from this plot?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample mean of the 2014 data set is larger than that for the 2005 data set. This may indicate that the overturn of the assault weapon ban in 2014 is associated with an increase in firearms mortality.\n",
    "\n",
    "However, the difference is relatively small, as are the sample sizes (50)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By performing EDA, we have gathered a lot of information and we may want to start answering some questions that require statistical hypothesis testing and modeling. \n",
    "\n",
    "* For example, for the firearm law example, we may *hypothesize* that the observed average difference are just based on random sampling from the underlying population, that is that the ban did not have an effect on firearm mortality rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The *null hypothesis* is that there is no real difference between the two data sets, and any differences are just based on random sampling from the underlying population.\n",
    "\n",
    "So, let's **assume that the two samples are from the same population**. \n",
    "\n",
    "* By combining the samples (called **pooling**), we get a new subset of the original population, if the null hypothesis is true. Moreover, any sample from this better represents the original population than either of the samples.\n",
    "\n",
    "* We can check whether the null hypothesis is true by checking how often samples from the pooled data set have a difference in means as large as the one observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Pooling</b>\n",
    "    \n",
    "**Pooling** describes the practice of gathering together small sets of data that are assumed to have been *drawn* from the same underlying population and using the combined larger set (the *pool*) to obtain a more precise estimate of that population.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The big question:** to sample **with replacement** or **without replacement**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Bootstrapping</b>\n",
    "    \n",
    "**Sampling with replacement** from a pooling set is called **bootstrapping** and is the most popular resampling technique. It is meant to better emulate independent sampling from the original population.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Permutations</b>\n",
    "    \n",
    "**Sampling without replacement** from a pooling set better emulates **permutation** tests, where we check every possible reordering of the data into samples. This will be discussed more later.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generally, *sampling without replacement* is more conservative (produces a higher $p$-value) than bootstrapping. \n",
    "* Bootstraping is **easy** and **most popular**, and we apply it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Bootstrap Idea:** The original sample approximates the population from which it was drawn. So *resamples* from this sample approximate what we would get if we took many samples from the population. The bootstrap distribution of a statistic, based on many resamples, approximates the sampling distribution of the statistic, based on many samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How would we randomly choose from this data **with replacement**?\n",
    "\n",
    "* And, if each resample is a new sample, which size should the resample have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recall that ```numpy.random``` has a similar method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a significance level of $\\alpha = 0.05$, let's build a Bootstrap simulation to compute the probability of observing a mean difference of 0.63 or larger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **What is the conclusion?**\n",
    "\n",
    "    * **Is the result statistically significant?** <!--No, because the p-value is larger than $\\alpha=0.05$.-->\n",
    "    * **Can we reject the null hypothesis?** <!--No, \"we cannot reject the null hypothesis\". -->\n",
    "    * **Conclusion:** <!--The data suggests that the ban did not have an effect of firearm mortality rate.-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more reasonable bootstrap approach would be to randomly assign values from 2005 or 2014 **for each state** and then assess the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively: Use the Pandas library\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to a special kind of array indexing: **fancy indexing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a significance level of $\\alpha = 0.05$, let's build a Bootstrap simulation to compute the probability of observing a mean difference of 0.63 or larger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **What is the conclusion?**\n",
    "\n",
    "    * **Is the result statistically significant?** <!--Yes, because the p-value is smaller than $\\alpha=0.05$.-->\n",
    "    * **Can we reject the null hypothesis?** <!--Yes, we reject the null hypothesis-->\n",
    "    * **Conclusion:** <!--Under this interpretation, the restriction on assault weapons is associated with an increase in mean firearms morality.-->\n",
    "    \n",
    "<!--It depends on how you interpret the data!-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of the bootstrap mean-difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time we create a bootstrap value for the difference of means, we create a new random value. Let's see how the bootstrap means are distributed by looking at a histogram of those values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few obervations:\n",
    "    \n",
    "1. The difference of means has a bell shape -- we saw that before. Why do you think that is?\n",
    "2. Almost all of the values fall between -0.5 and +0.5. Thus, it is not surprising that getting a mean-difference as large as 0.6 is very rare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic for later:** The **Central Limit Theorem** (CLT) for sums says that if you keep drawing larger and larger samples and taking their sums, the sums form their own normal distribution (the sampling distribution), which approaches a normal distribution as the sample size increases. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
