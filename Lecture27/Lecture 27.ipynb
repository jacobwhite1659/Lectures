{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 27 \n",
    "- Determinant\n",
    "- Matrix Inverse\n",
    "- Matrix Rank\n",
    "- Pseudo-Inverse\n",
    "- Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each system of linear equations can be represented by an **augmented matrix**. From the example in the last class, we have the following augmented matrix:\n",
    "\n",
    "\\begin{align*}\n",
    "\\left[\\begin{array}{ccc|c} 3 & 0 & 0 & 30\\\\ 1 & 2 & 0 & 18 \\\\ 0 & 1 & -1 & 2 \\end{array}\\right]\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <b>Augmented Matrices Operations</b>\n",
    "\n",
    "There are three elementary row operations we can do on augmented matrices:\n",
    "1. **Swap**: exchange any two rows of the augmented matrix (example: swap row 2 with row 3, $R2 \\leftarrow R3$)\n",
    "\n",
    "2. **Scale**: multiply any row by a non-zero constant (example: scale row 1 by $\\frac{1}{3}$, $R1 \\leftarrow \\frac{1}{3}R1$)\n",
    "\n",
    "3. **Pivot**: add a multiple of a row to another row (example: $R1 \\leftarrow R1 -3R2$)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row Echelon Form (R.E.F.)\n",
    "\n",
    "A matrix is said to be in **row echelon form** if:\n",
    "\n",
    "1. Each leading entry is equal to 1\n",
    "2. Each leading entry lies to the right of the leading entry above it (upper-diagonal matrices for square matrices)\n",
    "3. Rows containing zeros are at the bottom of the matrix\n",
    "\n",
    "For example,\n",
    "\n",
    "\\begin{align*}\n",
    "\\left[\\begin{array}{ccc}1 & -4 & 0 \\\\ 0 & 1 & 5 \\\\ 0 & 0 & 1\\end{array}\\right]\n",
    "\\end{align*}\n",
    "\n",
    "is a matrix in **row echelon form**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the **gaussian elimination** algorithm to reduce the augmented matrix into a **reduced row echelon form (R.R.E.F.)** matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a matrix is in row echelon form, in order to solve the system of linear equations, we can:\n",
    "\n",
    "1. Use back substitution\n",
    "2. Gauss-Jordan elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistent vs Dependent Systems\n",
    "\n",
    "A system of linear equations can have one solution, an infinite number of solutions, or no solution. Systems of equations can be classified by the number of solutions.\n",
    "\n",
    "* If a system has *at least one solution*, it is said to be **consistent**.\n",
    "\n",
    "* If a consistent system has *exactly one solution*, it is **independent**.\n",
    "\n",
    "* If a consistent system has an *infinite number of solutions*, it is **dependent**. When you graph the equations, both equations represent the same line.\n",
    "\n",
    "* If a system has *no solution*, it is said to be **inconsistent**. The graphs of the lines do not intersect, so the graphs are parallel and there is no solution.\n",
    "\n",
    "A system is said to be **independent** if the correspondent augmented matrix has a *unique* solution. This means that the matrix $\\mathbf{A}$ in our affine equation, $\\mathbf{\\mathbf{y}} = \\mathbf{A}\\mathbf{x}$ has **independent columns** (or rows) which correspond to independent or **informative features**.\n",
    "\n",
    "* Example: basis vectors\n",
    "\n",
    "A system is said to be **dependent** if the correspondent augmented matrix has *infinite* solutions. This means that the matrix $\\mathbf{A}$ in our affine equation, $\\mathbf{\\mathbf{y}} = \\mathbf{A}\\mathbf{x}$ has **dependent columns** (or rows). One or more columns are a **linear combination** of other columns. We can think of features to be **correlated**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "A system is **consistent** if and only if **no** row of the augmented matrix in row echelon form has its leading entry in the last column.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "The Gauss-Jordan elimination algorithm will allow us to determine whether our system is **independent** or **dependent**.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example\n",
    "\n",
    "1. Consider the following system of linear equations:\n",
    "\n",
    "\\begin{align*}\n",
    "\\begin{cases} 3x = 30 \\\\ x + 2y = 18 \\\\ y - z = 2\\end{cases}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Observation:** All columns (and rows) of the reduced row echelon form (rref) matrix are independent (the inner product is 0, which means they are orthogonal). We have a unique solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We are interested in finding out whether the linear transformation $\\mathbf{A}$ will *preserve* all dimensions $\\iff$ linearly independent columns $\\iff$ the system has a unique solution.\n",
    "\n",
    "In fact, we know that intersections between two lines (or hyperplanes) can happen in any of three different ways:\n",
    "1. the lines intersect at a unique point (i.e., solution exists and is unique),\n",
    "2. the lines are coincident (that is, the equations represent the same line and there are infinitely many points of intersection; in this case a solution exists, but is not unique), or\n",
    "3. the lines are parallel but not coincident (so that no solution exists)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Another matrix operation that would allow us to check if matrix $\\mathbf{A}$ has linearly independent columns (unique solution) is the **determinant** of $\\mathbf{A}$.\n",
    "\n",
    "Since this quantity *determines* whether or not the system has a unique solution, it is called the\n",
    "determinant of the coefficient matrix $\\mathbf{A}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Determinant of Matrix\n",
    "\n",
    "The **determinant** of a square $n\\times n$ matrix $\\mathbf{A}$ is a unique number. It measures the scaling factor by which the linear transformation $\\mathbf{A}$ changes any area or volume.\n",
    "\n",
    "The determinant of $\\mathbf{A}$ is denoted by $|\\mathbf{A}|$ or $\\det(\\mathbf{A})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider the linear transformations $\\mathbf{A} = \\left[\\begin{array}{cc} 3 & 0 \\\\ 0 & 2\\end{array}\\right]$ and $\\mathbf{A} = \\left[\\begin{array}{cc} 1 & 1 \\\\ 0 & 1\\end{array}\\right]$ \n",
    "\n",
    "*see virtual whiteboard*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For a $2\\times 2$ matrix \n",
    "\n",
    "$$\\mathbf{A} = \\left[\\begin{array}{cc}a & b \\\\ c & d\\end{array}\\right]$$\n",
    "\n",
    "the determinant is given by\n",
    "\n",
    "$$\\det(A) = |\\mathbf{A}| = ad - bc$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For a $3\\times 3$ matrix\n",
    "\n",
    "$$\\mathbf{A} = \\left[\\begin{array}{cc}a & b & c\\\\ d & e & f \\\\ g & h & i\\end{array}\\right]$$\n",
    "\n",
    "the determinant is given by\n",
    "\n",
    "$$\\det(A) = |\\mathbf{A}| = a(ei-fh) + b(fg - di) + c(dh - eg)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can generalize the determinant to any $n \\times n$ matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Some properties of the Determinant:\n",
    "\n",
    "1. $\\det(\\mathbf{I}) = 1$\n",
    "\n",
    "2. $\\det(\\mathbf{A}^T) = \\mathbf{A}$\n",
    "\n",
    "3. $\\det(\\mathbf{A}^{-1}) = \\frac{1}{\\det(\\mathbf{A})}$\n",
    "\n",
    "4. For square matrices $\\mathbf{A}$ and $\\mathbf{B}$ of equal size, $\\det(\\mathbf{A}\\mathbf{B}) = \\det(\\mathbf{A})\\det(\\mathbf{B})$\n",
    "\n",
    "5. $\\det(c\\mathbf{A}) = c^n\\det(\\mathbf{A})$ for an $n\\times n$ matrix $\\mathbf{A}$ and constant c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Observation:** This linear transformation will invert the direction and scale any area by a factor of 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**<font color=blue>Example 2</font> Consider the following system of linear equations:**\n",
    "\n",
    "$$\\begin{cases} 4x-4y-z=-10\\\\ 8x-8y-2z=-20 \\\\ 4x+12y-5z=14 \\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "M = Matrix([[4,-4,-1,-10],[8,-8,-2,-20],[4,12,-5,14]])\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Observations:** \n",
    "\n",
    "* The linear transformation $\\mathbf{A}$ only has 2 linearly independent columns (this can be easily seen from the system of equations). \n",
    "\n",
    "* The determinant of this transformation will be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Does this system have a solution?\n",
    "\n",
    "<!-- Yes, an infinite number of solutions. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**<font color=blue>Example 3</font> Consider the following system of linear equations:**\n",
    "\n",
    "$$\\begin{cases} 4x-4y-z=-6\\\\ 12x+4y-7z=22 \\\\ 4x+12y-5z=2 \\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "M = Matrix([[4,-4,-1,-6],[12,4,-7,22],[4,12,-5,2]])\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Does this system have a solution?\n",
    "\n",
    "<!-- This system is inconsistent, it does not have a solution.  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inverse of a Matrix\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "If the square matrix $\\mathbf{A}$ has:\n",
    "\n",
    "* **linearly independent columns**, then the matrix $\\mathbf{A}$ is said to be **left-invertible**, that is, there exists a inverse matrix $\\mathbf{A}^{-1}$ such that $\\mathbf{A}^{-1}\\mathbf{A} = \\mathbf{I}$.\n",
    "    \n",
    "* **linearly independent rows**, then the matrix $\\mathbf{A}$ is said to be **right-invertible**, that is, there exists a inverse matrix $\\mathbf{A}^{-1}$ such that $\\mathbf{A}\\mathbf{A}^{-1} = \\mathbf{I}$.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If the linear transformation $\\mathbf{A}$ is invertible, then we can compute a solution directly as:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{A}\\mathbf{x} &= \\mathbf{b} \\\\\n",
    "\\mathbf{A}^{-1}\\mathbf{A}\\mathbf{x} &= \\mathbf{A}^{-1}\\mathbf{b}\\\\\n",
    "\\mathbf{I}\\mathbf{x} &= \\mathbf{A}^{-1}\\mathbf{b}\\\\\n",
    "\\mathbf{x} &= \\mathbf{A}^{-1}\\mathbf{b}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the moment, we will focus on the special case where $\\mathbf{A}$ is square ($n \\times n$). But we will see that if $\\mathbf{A}$ is not square, we need to find a special matrix inverse called *pseudo-inverse*.\n",
    "\n",
    "In this case, if $\\mathbf{A}$ is invertible, then $\\mathbf{x}$ is a unique solution to the equation $\\mathbf{Ax} = \\mathbf{b}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=blue>Example 4</font> Consider the system of linear equations from last class:**\n",
    "\n",
    "\\begin{cases} 3x_1 =30 \\\\ x_1 + 2x_2 = 18 \\\\ x_2 - x_3 = 2 \\end{cases}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create augmented matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that $\\mathbf{M}$ is a system of linearly independent equations with solutions\n",
    "\n",
    "\\begin{cases} x_1 = 10 \\\\ x_2 = 4 \\\\ x_3 = 2 \\end{cases}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, we know that we could find these same solutions if we knew $\\mathbf{A}^{-1}$ as\n",
    "$$\n",
    "\\mathbf{x} = \\mathbf{A}^{-1} \\mathbf{b}\n",
    "$$\n",
    "\n",
    "Let's see how we can find $\\mathbf{A}^{-1}$ by extending the Gauss-Jordan algorithm: *On electronic whiteboard*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how we can use sympy's RREF to find the matrix inverse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the matrix inverse in numpy using the ```numpy.linalg.inv()``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If finding the inverse via Gauss-Jordan reduction already finds the solution to a system of linear equations, what is the advantage of finding the matrix inverse?\n",
    "\n",
    "* After finding $\\mathbf{A}^{-1}$ once, can find the solution to $\\mathbf{Ax} = \\mathbf{b}_i$ for many different $\\mathbf{b}_i$ $\\mbox{easily}^{1}$.\n",
    "* Can find $\\mathbf{A}^{-1}$ with other algorithms at lower complexity than Gauss-Jordan.\n",
    "* Matrix inverse plays an important role in **linear regression**, where we want to find the solution to an over-determined set of equations.\n",
    "\n",
    "*$\\mbox{}^1$ Note that in general, using matrix inverses to solve a system of linear equations is usually discouraged because of problems with numerical accuracy. However, for our purposes, using matrix inverses for this purpose will always be acceptable.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Case: $2 \\times 2$ Matrices\n",
    "\n",
    "In future classes, you may be required to find a matrix inverse by manual computation. \n",
    "\n",
    "In this class, I will only teach you how to find the inverse of a $2 \\times 2$ matrix by hand.\n",
    "\n",
    "(For any classes that require inversion of a $3 \\times 3$ matrix, you can find the required manipulations in many places online.)\n",
    "    \n",
    "*See electronic whiteboard*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=blue>Example 5</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2=np.array([[2,7], [1,6]])\n",
    "\n",
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Case: Diagonal Matrices\n",
    "\n",
    "Let $\\mathbf{D}$ be a diagonal matrix:\n",
    "\n",
    "\\begin{align*}\n",
    "D &= \\operatorname{diag}(d_0,d_1,\\dots,d_{n-1}) = \\left[\\begin{array}{cccc}d_0 & 0 &\\dots & 0\\\\ 0 & d_1 & \\dots & 0\\\\ \\vdots & \\vdots & \\ddots & \\vdots\\\\0 & 0 & \\dots & d_{n-1}\\end{array}\\right]\n",
    "\\end{align*}\n",
    "\n",
    "Its matrix inverse is:\n",
    "\n",
    "\\begin{align*}\n",
    "D^{-1} &= \\operatorname{diag}\\left(\\frac{1}{d_0},\\frac{1}{d_1},\\dots,\\frac{1}{d_{n-1}}\\right) = \\left[\\begin{array}{cccc}\\frac{1}{d_0} & 0 &\\dots & 0\\\\ 0 & \\frac{1}{d_1} & \\dots & 0\\\\ \\vdots & \\vdots & \\ddots & \\vdots\\\\0 & 0 & \\dots & \\frac{1}{d_{n-1}}\\end{array}\\right]\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Case: Orthogonal Matrices\n",
    "\n",
    "Recall that the Gram-Schmidt algorithm found a set of *orthonormal basis vectors*.\n",
    "\n",
    "**Orthonormal** means both: \n",
    "* the vectors are orthogonal $\\mathbf{a}_{i}^{T} \\mathbf{a}_j=0,~~ i \\ne j$\n",
    "* the vectors are normalized $\\forall i, ~ \\| \\mathbf{a}_i \\|^2 =1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have $n$ $n$-vectors, then we can check both of these conditions simultaneously if we hstack the vectors into a matrix \n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{A} = \\begin{bmatrix} \\mathbf{a}_0 | & \\mathbf{a}_1 | & \\dots | & \\mathbf{a}_{n-1} \\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "as\n",
    "\\begin{align*}\n",
    "\\mathbf{A}^T \\mathbf{A} = \\mathbf{I}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    <b>Orthogonal Matrix</b>\n",
    "    \n",
    "An $n \\times n$ matrix $\\mathbf{A}$ is an *orthogonal matrix* if it satisfies\n",
    "\\begin{align*}\n",
    "\\mathbf{A}^T \\mathbf{A} = \\mathbf{I}\n",
    "\\end{align*}\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    <b>Gram Matrix</b>\n",
    "    \n",
    "For a matrix $\\mathbf{A}$, the matrix $\\mathbf{A}^T \\mathbf{A}$ is called the **Gram matrix**.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, a square matrix is orthogonal if its Gram matrix is the identity matrix.\n",
    "\n",
    "* Note that the Gram matrix is defined even for matrices that are not square!\n",
    "\n",
    "* Note that the equation $\\mathbf{A}^T \\mathbf{A} = \\mathbf{I}$ implies that the inverse of an orthogonal matrix $\\mathbf{A}$ is its transpose!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For general $m \\times n$ matrices, they may have left inverses,  right inverses, both, or no inverse matrix.\n",
    "\n",
    "If a matrix $\\mathbf{A}$ has both a left inverse $\\mathbf{Y}$ and a right inverse $\\mathbf{X}$, then we say the matrix is *invertible* and denote $\\mathbf{X}=\\mathbf{Y}$ by $\\mathbf{A}^{-1}$.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "Only square matrices ($n \\times n$) can have both (and the same) left and right inverses.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a matrix $\\mathbf{A}$ is square, then the following are equivalent:\n",
    "1. $\\mathbf{A}$ is invertible\n",
    "2. The *columns* of $\\mathbf{A}$ are linearly independent\n",
    "3. The *rows* of $\\mathbf{A}$ are linearly independent\n",
    "4. $\\mathbf{A}$ has a left inverse\n",
    "5. $\\mathbf{A}$ has a right inverse\n",
    "6. $|\\mathbf{A}|\\neq 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the columns of $\\mathbf{A}$ are linearly independent, we know they form a **basis** for $\\mathbf{R}^n$!\n",
    "\n",
    "(as do the rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Properties of Matrix Inverse\n",
    "\n",
    "1. If $\\mathbf{A}$ is invertible, then its transpose is also invertible and\n",
    "\n",
    "\\begin{align*}\n",
    "\\left (\\mathbf{A}^T \\right)^{-1} = \\left(\\mathbf{A}^{-1} \\right)^T\n",
    "\\end{align*}\n",
    "\n",
    "2. If $\\mathbf{A}$ and $\\mathbf{B}$ are $n \\times n$ invertible matrices, then\n",
    "\n",
    "\\begin{align*}\n",
    "\\left(\\mathbf{AB}\\right)^{-1} = \\mathbf{B}^{-1} \\mathbf{A}^{-1}\n",
    "\\end{align*}\n",
    "\n",
    "Check:\n",
    "\\begin{align*}\n",
    "\\left(\\mathbf{AB}\\right)^{-1} \\left(\\mathbf{AB}\\right) &=\n",
    "\\mathbf{B}^{-1} \\mathbf{A}^{-1}\\left(\\mathbf{AB}\\right)\\\\\n",
    "&= \\mathbf{B}^{-1} \\left( \\mathbf{A}^{-1} \\mathbf{A} \\right)\\mathbf{B}\\\\\n",
    "&=\\mathbf{B}^{-1} \\mathbf{I} \\mathbf{B}\\\\\n",
    "&=\\mathbf{B}^{-1} \\mathbf{B} \\\\\n",
    "&=\\mathbf{I}\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=blue>Example </font> Given a random, invertible $3 \\times 3$ matrix $\\mathbf{A}$, find the coefficients to represent $\\mathbf{x}=[3, 7, 9]^T$ as a linear combination of the columns of $\\mathbf{A}$:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr.seed(7)\n",
    "\n",
    "A = npr.randint(10,size=(3,3))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can do all those operations in one matrix-vector multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Application: Polynomial Interpolation\n",
    "\n",
    "(Read [Boyd's book Section 11.4](http://vmls-book.stanford.edu/vmls.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Suppose we have a set of data points $(x_i,y_i)$, $i=1,2, \\ldots n$.\n",
    "\n",
    "For a set of $n$ data points, we can always find a polynomial of degree $n-1$ that can fit those data points.\n",
    "\n",
    "(For example, we can draw a line through any two points in the plane.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here we show how to find that polynomial.\n",
    "\n",
    "Let the polynomial be \n",
    "\n",
    "\\begin{align*}\n",
    "p(x) = c_0 x^0 + c_1 x^1 +c_2 x^2 + \\ldots + c_{n-1} x^{n-1}\n",
    "\\end{align*}\n",
    "\n",
    "Then we want to find the values of $c_0, c_1, \\ldots, c_{n-1}$ that solve the set of equations:\n",
    "\\begin{align*}\n",
    "\\\\p(x_0) &= y_0 \\\\\n",
    "p(x_1) &= y_1 \\\\\n",
    "&\\vdots\\\\\n",
    "p(x_{n-1}) &= y_{n-1} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "At first glance, this may seem to be a set of **nonlinear** equations. But that is not the case, because the powers of $x_i$ are all **deterministic constants**.\n",
    "\n",
    "So, we get linear equations in the coefficients $c_i$'s!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let \n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{A} = \\begin{bmatrix} 1 & x_0 & x_{0}^2 & x_{0}^3 & \\cdots \\\\ 1 & x_1 & x_{1}^2 & x_{1}^3 & \\cdots \\\\ \\vdots & \\vdots & \\vdots & \\vdots & \\cdots\\\\ 1 & x_{n-1} & x_{n-1}^2 & x_{n-1}^3 & \\cdots \\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "and let\n",
    "\n",
    "* $\\mathbf{c} = \\left[ c_0, c_1, \\ldots c_{n-1} \\right]^T$ be the vector of coefficients\n",
    "* $\\mathbf{y} = \\left[ y_0, y_1, \\ldots y_{n-1} \\right]^T$ be the vector of $y$-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then the coefficients satisfy \n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{A}\\mathbf{c} = \\mathbf{y}\n",
    "\\end{align*}\n",
    "\n",
    "If $\\mathbf{A}$ is invertible, then \n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{c} = \\mathbf{A}^{-1} \\mathbf{y}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's try an example. Suppose we have the following data observations:\n",
    "\n",
    "\\begin{align*}\n",
    "(x,y): ~~~ (1,3),~~~ (2, -1), ~~~ (3,2) ~~~ (4,1)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is $\\mathbf{A}$ invertible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank of a Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we try to fit this with fewer coefficents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we only have 2 independent vectors, so they do not form a basis for $\\mathbb{R}^4$.\n",
    "\n",
    "In general, we cannot find a solution, and we cannot use the matrix inverse to find the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generally the case for linear transformation $\\mathbf{A}$ that are not **full rank**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    <b>Matrix Rank</b>\n",
    "    \n",
    "The **rank** of a matrix $\\mathbf{A}$ is the **dimension of the vector space** generated (or spanned) by its columns. \n",
    "    \n",
    "The rank of a matrix $\\mathbf{A}$ corresponds to the maximal number of **linearly independent columns** of $\\mathbf{A}$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We denote the rank of a matrix $\\mathbf{A}$ as:\n",
    "\n",
    "$$\\operatorname{rk}(\\mathbf{A}) \\text{ or } \\operatorname{rank}(\\mathbf{A})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a matrix $\\mathbf{A}$ of size $n\\times m$:\n",
    "\n",
    "$$\\operatorname{rank}(\\mathbf{A}) \\leq \\min(n,m)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix is said to have **full rank** if its rank equals the largest possible dimension, that is, $\\max(n,m)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A3 = np.array([[1,1,2],[1,2,4],[1,3,6]])\n",
    "A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares: Approximate Solutions to Over-Determined Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\mathbf{A}$ is a tall matrix with independent columns and $\\mathbf{Ax}=\\mathbf{b}$ is overconstrained, there is no solution $\\mathbf{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at these equations\n",
    "\n",
    "$$ \\begin{bmatrix} 1 & 1\\\\ 1 & 2 \\\\ 1 & 3\\\\ 1 & 4 \\end{bmatrix} \\begin{bmatrix} x \\\\ y\\\\ \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ -1 \\\\ 2 \\\\ 1 \\end{bmatrix} $$\n",
    "\n",
    "$$\\begin{cases} x+y &= 3\\\\ x +2y &= -1 \\\\ x+ 3y &=2 \\\\x + 4y &= 1 \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving for $y$:\n",
    "\n",
    "$$\\begin{cases} y &= -x + 3\\\\ y &= -\\frac{1}{2}x - \\frac{1}{2} \\\\ y &= -\\frac{1}{3}x + \\frac{2}{3} \\\\ y &= -\\frac{1}{4}x + \\frac{1}{4} \\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xln=np.linspace(0,10)\n",
    "\n",
    "y1 = -xln + 3\n",
    "y2 = -1/2*xln - 1/2\n",
    "y3 = -1/3*xln + 2/3\n",
    "y4 = -1/4*xln + 1/4\n",
    "\n",
    "plt.plot(xln,y1, xln,y2, xln,y3, xln,y4)\n",
    "plt.legend(['$y_1$','$y_2$','$y_3$','$y_4$'],fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, there is no single solution to this system of equations.\n",
    "\n",
    "We try to minimize the residual error\n",
    "\n",
    "$$\\mathbf{r} = \\mathbf{Ax}-\\mathbf{b}$$\n",
    "\n",
    "As usual, we minimize a squared error, the squared norm is given as:\n",
    "\n",
    "$$ \\left\\| \\mathbf{Ax}-\\mathbf{b} \\right\\|^2 =  \\left\\| \\mathbf{r} \\right\\|^2 = r_{0}^{2} + r_{1}^{2} + \\cdots + r_{n-1}^{2}$$\n",
    "\n",
    "The problem is sometimes called **<font color=blue>linear least squares</font>** because $\\mathbf{r}$ is an **affine function** of $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two basic ways to view this problem are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Interpretation\n",
    "\n",
    "The vector $\\mathbf{x}$ can be viewed as the coefficients to linearly combine the columns of $\\mathbf{A}$ to form a vector \"close to\" $\\mathbf{b}$:\n",
    "\n",
    "$$\n",
    "\\left\\| \\mathbf{Ax}-\\mathbf{b} \\right\\|^2 =\n",
    "\\left\\|  \\left( x_0 \\mathbf{a}_0 + x_1 \\mathbf{a}_1 + \\cdots + x_{n-1} \\mathbf{a}_{n-1} \\right) -\\mathbf{b}\n",
    "\\right\\|^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the rows of $\\mathbf{A}$ be $\\tilde{\\mathbf{a}}_{0}^{T}, \\tilde{\\mathbf{a}}_{1}^{T}, \\ldots, \\tilde{\\mathbf{a}}_{n-1}^{T}$.\n",
    "\n",
    "Then the residual components are\n",
    "\n",
    "$$ r_i = \\tilde{\\mathbf{a}}_{i}^{T} \\mathbf{x} - b_i $$\n",
    "\n",
    "The least-squares objective is then\n",
    "\n",
    "$$ \\left\\| \\mathbf{Ax}-\\mathbf{b} \\right\\|^2 = \n",
    "(\\tilde{\\mathbf{a}}_{0}^{T} \\mathbf{x} - b_0)^2  + \n",
    "(\\tilde{\\mathbf{a}}_{1}^{T} \\mathbf{x} - b_1)^2 + \\cdots + \n",
    "(\\tilde{\\mathbf{a}}_{n-1}^{T} \\mathbf{x} - b_{n-1})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytical Solution\n",
    "\n",
    "We can find the minimum using calculus.\n",
    "\n",
    "Let $f(\\mathbf{x}) = \\left\\| \\mathbf{Ax} - \\mathbf{b} \\right\\|^2$\n",
    "\n",
    "Then any minimum solution $\\hat{\\mathbf{x}}$ will satisfy:\n",
    "\n",
    "\\begin{align*} \\frac{\\partial f}{\\partial x_i} (\\hat{x}) =0, ~~~ i=0,1,\\ldots,n-1 \\end{align*}\n",
    "\n",
    "Or, using gradient notation:\n",
    "\n",
    "\\begin{align*} \\nabla f(\\hat{\\mathbf{x}}) =0 \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without going into details of the matrix calculus (see pp. 184-185 and pp. 228-230 in Boyd's textbook), the gradient of $f(\\mathbf{x})$ is\n",
    "\n",
    "\\begin{align*}\\nabla f(\\mathbf{x}) = 2 \\mathbf{A}^T \\left( \\mathbf{Ax} -b \\right) \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the gradient equal to zero and distributing, we have:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{A}^T\\mathbf{Ax} - \\mathbf{A}^T\\mathbf{b} &=0 \\\\\n",
    "\\Rightarrow \\mathbf{A}^T\\mathbf{Ax} &=\\mathbf{A}^T\\mathbf{b} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "These are called the **<font color=blue>normal equations</font>**.\n",
    "\n",
    "If the columns of $\\mathbf{A}$ are linearly independent, then the Gram matrix is invertible, and the solution is\n",
    "\n",
    "\\begin{align*} \\hat{\\mathbf{x}} = \\left( \\mathbf{A}^T \\mathbf{A} \\right)^{-1} \\mathbf{A}^T \\mathbf{b} \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix products in the last equation should look pretty familiar. They are the **<font color=blue>pseudoinverse</font>**:\n",
    "\n",
    "\\begin{align*} \\hat{\\mathbf{x}} = \\mathbf{A}^\\dagger \\mathbf{b} \\end{align*}\n",
    "\n",
    "where \n",
    "\n",
    "\\begin{align*}\\mathbf{A}^{\\dagger} = (\\mathbf{A}^T\\mathbf{A})^{-1}\\mathbf{A}^T\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    <b>Pseudoinverse for Tall Matrices</b>\n",
    "    \n",
    "An $n \\times m$ ($n>m$) tall matrix $\\mathbf{A}$ with **linearly independent columns** has a left-inverse and it's called the **pseudoinverse**:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{A}^{\\dagger} = (\\mathbf{A}^T\\mathbf{A})^{-1}\\mathbf{A}^T\n",
    "\\end{align*}\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    <b>Pseudoinverse for Wide Matrices</b>\n",
    "    \n",
    "An $m \\times n$ ($n<m$) wide matrix $\\mathbf{A}$ with **linearly independent rows** has a right-inverse and it's called the **pseudoinverse**:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{A}^{\\dagger} = \\mathbf{A}^T(\\mathbf{A}\\mathbf{A}^T)^{-1}\n",
    "\\end{align*}\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try an example. Suppose we have the following data observations:\n",
    "\n",
    "\\begin{align*}\n",
    "(x,y): ~~~ (1,3),~~~ (2, -1), ~~~ (3,2) ~~~ (4,1)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]]),\n",
       " array([[ 3],\n",
       "        [-1],\n",
       "        [ 2],\n",
       "        [ 1]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2,3,4]]).T\n",
    "\n",
    "y = np.array([[3,-1,2,1]]).T\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD1CAYAAAC1BoUqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAnRklEQVR4nO2df2zj533fXx9TpMRKIq0frKQ66V3huNPcAE1jz3GQYbGtds3dinnTUsAZltwCFUUKteiwFsW1BZK2QFH/URRLliLusAQ9Y12CAE1TI7WXpbGdtICSttKcxJ7r9RyYuJtEiaRo/pBIUcd79od4msKjTsrx+73v5/vg8wKII/k8/D6f1z3SW+SXD/mIcw7DMAzDT+6KugDDMAwjPCzkDcMwPMZC3jAMw2Ms5A3DMDzGQt4wDMNjLOQNwzA8ZijqAo7y4osvuuHh4ajLMAzDiBW7u7ulhYWFXL82VSE/PDzM/Pz8bT02n89z5syZgCuKBnPRhy8eYC5aGcRlbW0tf1ybN6drkslk1CUEhrnowxcPMBethOXiTchns9moSwgMc9GHLx5gLloJy8WbkC+VSlGXEBjmog9fPMBctBKWizchb3/RdeKLiy8eYC5aUftMXkRGRORvRORbIvKKiPx2nz4iIp8Qkcsi8m0Reeeg4/bSbreDPmRkmIs+fPEAc9FKWC5BrK7ZAx5zzjVEJAn8tYg855z7xpE+54D7upd3AZ/q/jswG7U9Lq1uMN2pUErscuGBOeYy8V6G2Ww2oy4hMHxx8cUDzEUrYbkMHPLu4LuKG92bye6l9/uLHwee7vb9hojcLSJzzrmNQcbeqO1x8bnLbNTbjA1dp3GtwqtbOzx57m2xDvrZ2dmoSwgMX1x88QBz0UpYLoGckxeRhIi8BGwBX3HOfbOnyz3AlSO3r3bvG4hLqxts1A9e4jxw9zUANuptLq0O9LcjcgqFQtQlBIYvLr54gLloJSyXQD4M5ZzrAO8QkbuBPxORtzvnXj7SRfo9rPeOra0tlpaWGBoaotPpsLi4yPLyMoVCgdHRURKJBLVajVwux/b2NpOdN8kmr/OO7DXSCcePjl1jbuQ6u80WV65cQUSYnJykWCySyWTodDrs7OwwOztLoVAgmUySzWYplUpks1na7TbNZvOwPZVKMT4+TrlcZmJigmazSavVOmwfGRkhnU5TqVSYmpqiXq/TbrcP29PpNKlUimq1yvT0NNVqlf39/cP2fk7OOUSEfD7P2NgYAI1Gg5mZGYrFYuycdnd3uXLlCrlcjs3Nzdg6Xbt2jXw+/z3zFFenRqNBqVTq+7MXN6dGo8He3t4tf5/i4uScY319/VQZ0et0KyTonaFE5GPAjnPu94/c90fAi865z3ZvvwY80nu6ZmVlxX0/n3h98oU3eP71CgBzwx029hIAPHbvBBcfPTugSXQ0Go1TTV4c8MXFFw8wF60M4rK2tra6sLDwYL+2IFbX5LrP4BGRNPCTwN/3dHsG+FB3lc3DQHXQ8/HAwZus4ykAfnS8A8DceIoLD8wNeuhIKZfLUZcQGL64+OIB5qKVsFyCOF0zB1wSkQQHfzQ+75z7koh8BMA59xTwLHAeuAzsAh8OYFzmMsM8ee5tXFrd4PreDo/dO+rF6pqJiYmoSwgMX1x88QBz0UpYLkGsrvk28BN97n/qyHUHLA86Vj/mMsNcfPQsm5ubzMzMhDHEHafZbJLJZKIuIxB8cfHFA8xFK2G5ePOJ11arFXUJgWEu+vDFA8xFK2G5eBPytl5WJ764+OIB5qIV1evkNWDrZXXii4svHmAuWgnLxZuQHxkZibqEwDAXffjiAeailbBcvAn5dDoddQmBYS768MUDzEUrYbl4E/KVSiXqEgLDXPThiweYi1bCcvEm5KempqIuITDMRR++eIC5aCUsF29Cvl6vR11CYJiLPnzxAHPRSlgu3oS8bR6gE19cfPEAc9FKWC7ehLytl9WJLy6+eIC5aMXWyZ+ArZfViS8uvniAuWjF1smfgC2l0okvLr54gLloxZZQnkAqlYq6hMAwF3344gHmopWwXLwJ+Wq1GnUJgWEu+vDFA8xFK2G5eBPy09PTUZcQGOaiD188wFy0EpaLNyFvf9F14ouLLx5gLlpR+0xeRN4qIi+IyKsi8oqI/HKfPo+ISFVEXupePjrouL3s7+8HfcjIMBd9+OIB5qKVsFyC2P7vGvArzrk1ERkHVkXkK865/93T76+ccz8TwHh9sfWyOvHFxRcPMBetqF0n75zbcM6tda/XgVeBewY97veLrZfViS8uvniAuWglLJcgnskfIiJnOdjv9Zt9mt8tIt8C1oFfdc690ttha2uLpaUlhoaG6HQ6LC4usry8TKFQYHR0lEQiQa1WI5fLsb29jXOOXC7H5uYm169fp1wu02g0mJmZoVgsIiJMTk5SLBbJZDJ0Oh12dnaYnZ2lUCiQTCbJZrOUSiWy2Sztdptms3nYnkqlGB8fp1wuMzExQbPZpNVqHbaPjIyQTqepVCpMTU1Rr9dpt9uH7el0mlQqRbVaZXp6mmq1yv7+/mH7cU7JZJJ8Ps/Y2BhArJ1arRZXrlw5nKe4OjnnyOfzfX/24ua0u7tLqVS65e9TXJx2d3fZ29s7VUZod0okEqyvr58qI3qdbpnLB3tsD46IjAFfA37XOfeFnrYMcN051xCR88DHnXP39R5jZWXFzc/P39b4lUrFm53bzUUfvniAuWhlEJe1tbXVhYWFB/u1BbK6RkSSwJ8Cf9Ib8ADOuZpzrtG9/iyQFJFA1wvVarUgDxcp5qIPXzzAXLQSlksQq2sE+DTwqnPuD47pM9vth4g81B23POjYR8nlckEeLlLMRR++eIC5aCUslyCeyb8H+CDw2JElkudF5CMi8pFun/cDL3fPyX8CeMIFdZ6oy/b2dpCHixRz0YcvHmAuWgnLZeA3Xp1zfw3ICX0+CXxy0LFOGCPMw99RzEUfvniAuWglLBdvPvFqL9t04ouLLx5gLlrRfLpGBZubm1GXEBjmog9fPMBctBKWizchf5r1onHBXPThiweYi1bCcvEm5A3DMIyb8SbkG41G1CUEhrnowxcPMBethOXiTcjPzMxEXUJgmIs+fPEAc9FKWC7ehHyxWIy6hMAwF3344gHmopWwXLwJ+e4Har3AXPThiweYi1bCcvEm5CcnJ6MuITDMRR++eIC5aCUsF29C3l626cQXF188wFy0YqdrTiCTyURdQmCYiz588QBz0UpYLt6EfKfTibqEwDAXffjiAeailbBcvAn5nZ2dqEsIDHPRhy8eYC5aCcvFm5C3DX114ouLLx5gLlpRu5G3FmxDX5344uKLB5iLVsJy8Sbkk8lk1CUEhrnowxcPMBethOUy8KYhIvJW4GlgFrgO/Bfn3Md7+gjwceA8sAv8e+fc2qBjHyWbzQZ5uEgxF3344LFR2+PS6gbt1i6p19pceGCOucxw1GUNhA/zcoOwXIJ4Jn8N+BXn3D8GHgaWReT+nj7ngPu6l58HPhXAuN9DqVQK+pCRYS76iLvHRm2Pi89d5vnXKyT26jz/eoWLz11mo7YXdWkDEfd5OUpYLgOHvHNu48azcudcHXgVuKen2+PA0+6AbwB3i8jcoGMfxf6i68QXl7h7XFrdYKPeBuCN3QQAG/U2l1Y3oixrYOI+L0cJy2Xg0zVHEZGzwE8A3+xpuge4cuT21e593/MTtrW1xdLSEkNDQ3Q6HRYXF1leXqZQKDA6OkoikaBWq5HL5dje3sY5Ry6XY3Nzk06nQ6fTodFoMDMzQ7FYRESYnJykWCySyWTodDrs7OwwOztLoVAgmUySzWYplUpks1na7TbNZvOwPZVKMT4+TrlcZmJigmazSavVOmwfGRkhnU5TqVSYmpqiXq/TbrcP29PpNKlUimq1yvT0NNVqlf39/cP245zuuusuqtXq4SYCcXYqFArU6/XDeYqrU71ep1qt9v3Zi4NT5lqV9063WX1ziIcm9kknHPvXYbpTYXf3B2PpVK1WefPNN0mn06fKCO1Od911F7u7u6fKiF6nW+ZyUJvHisgY8DXgd51zX+hp+wvg97qbfiMiXwV+zTm3erTfysqKm5+fv63x8/k8Z86cua3HasNc9BF3jydfeIPnX68A8N7pNl8rpQB47N4JLj56NsLKBiPu83KUQVzW1tZWFxYWHuzXFsjqGhFJAn8K/ElvwHe5Crz1yO23AOtBjH0DWy+rE19c4u5x4YE55sYPgn31zYMX8HPjKS48EOhZ0ztO3OflKGrXyXdXznwaeNU59wfHdHsG+JAc8DBQdc4FejLQ1svqxBeXuHvMZYZ58tzbeOzeCc6/5S4eu3eCJ8+9Lfara+I+L0cJyyWIc/LvAT4IfEdEXure9xvADwM4554CnuVg+eRlDpZQfjiAcb+HVCoV9CEjw1z04YPHXGaYi4+eZWNjmLm5eD+Dv4EP83KDsFwGDvnuefZbftu9OzjxvzzoWLdifHw8zMPfUcxFH754gLloJSwXbz7xWi6Xoy4hMMxFH754gLloJSwXb0J+YmIi6hICw1z04YsHmItWwnLxJuSbzWbUJQSGuejDFw8wF62E5eJNyLdarahLCAxz0YcvHmAuWgnLxZuQt/WyOvHFxRcPMBetqF0nrwVbL6sTX1x88QBz0Yp9n/wJjIyMRF1CYJiLPnzxAHPRSlgu3oR8Op2OuoTAMBd9+OIB5qKVsFy8CflKpRJ1CYFhLvrwxQPMRSthuXgT8lNTU1GXEBjmog9fPMBctBKWizchX6/Xoy4hMMxFH754gLloJSwXb0K+3W5HXUJgmIs+fPEAc9FKWC7ehLytl9WJLy6+eIC5aMXWyZ+ArZfViS8uvniAuWjF1smfgC2l0okvLr54gLloRfUSShH5jIhsicjLx7Q/IiJVEXmpe/loEOMexTYP0IkvLr54gLloJSyXoJ7J/zHwvhP6/JVz7h3dy+8ENO4h1Wo16ENGhrnowxcPMBethOUSSMg7574ObAdxrNtleno6yuEDxVz04YsHmItWwnK5k+fk3y0i3xKR50Tkx4I+uP1F14kvLr54gLloJSyXIDbyPg1rwBnnXENEzgNfBO7r7bS1tcXS0hJDQ0N0Oh0WFxdZXl6mUCgwOjpKIpGgVquRy+XY3t7GOUcul2Nzc5Nms8nw8DCNRoOZmRmKxSIiwuTkJMVikUwmQ6fTYWdnh9nZWQqFAslkkmw2S6lUIpvN0m63aTabh+2pVIrx8XHK5TITExM0m01ardZh+8jICOl0mkqlwtTUFPV6nXa7fdieTqdJpVJUq1Wmp6epVqvs7+8fth/n1G63yefzjI2NAcTaqVwu0+l0Ducprk61Wo39/f2+P3txcyqVSqRSqVv+PsXFqVQqMTU1daqM0O7UbrdZX18/VUb0Ot0KOdhje3BE5CzwJefc20/R9w3gQedc6ej9Kysrbn5+/rbG39vbY3h4+LYeqw1z0YcvHmAuWhnEZW1tbXVhYeHBfm135HSNiMyKiHSvP9QdN9Bda229rE58cfHFA8xFK2G5BHK6RkQ+CzwCTIvIVeBjQBLAOfcU8H7gF0TkGtAEnnBBvYToMjo6GuThIsVc9OGLB5iLVsJyCSTknXMfOKH9k8AngxjrOBKJRJiHv6OYiz588QBz0UpYLt584rVWq0VdQmCYiz588QBz0UpYLt6EfC6Xi7qEwDAXffjiAeailbBcvAn57e1IP4sVKOaiD188wFy0EpaLNyEf8Pu4kWIu+vDFA8xFK2G5eBPy9rJNJ764+OIB5qIVO11zApubm1GXEBjmog9fPMBctBKWizchf5qP98YFc9GHLx5gLloJy8WbkDcMwzBuxpuQbzQaUZcQGOaiD188wFy0EpaLNyE/MzMTdQmBYS768MUDzEUrYbl4E/LFYjHqEgLDXPThiweYi1bCcvEm5LtfcukF5qIPXzzAXLQSlos3IT85ORl1CYFhLvrwxQPMRSthuXgT8vayTSe+uPjiAeaiFTtdcwKZTCbqEgLDXPThiweYi1bCcvEm5DudTtQlBIa56MMXDzAXrYTlEkjIi8hnRGRLRF4+pl1E5BMicllEvi0i7wxi3KPs7OwEfcjIMBd9+OIB5qKVsFwC2RkK+GMOdn56+pj2c8B93cu7gE91/w2M2dnZIA8XKeaiD188wFy0sVHb49LqBjvNFqPffYMLD8wxlwluc/JAnsk7574O3OrLkB8HnnYHfAO4W0Tmghj7Brahr058cfHFA8xFExu1PS4+d5nnX68w0q7y/OsVLj53mY3aXmBj3Klz8vcAV47cvtq9LzCSyWSQh4sUc9GHLx5gLpq4tLrBRr0NwG7nYJ38Rr3NpdWNwMYI6nTNSfRb5X/TN+RvbW2xtLTE0NAQnU6HxcVFlpeXKRQKjI6OkkgkqNVq5HI5tre3cc6Ry+XY3NwkmUxSLpdpNBrMzMxQLBYRESYnJykWi2QyGTqdDjs7O8zOzlIoFEgmk2SzWUqlEtlslna7TbPZPGxPpVKMj49TLpeZmJig2WzSarUO20dGRkin01QqFaampqjX67Tb7cP2dDpNKpWiWq0yPT1NtVplf3//sP04p9HRUfL5/OG30sXZqdVqceXKlcN5iquTiJDP5/v+7MXNaXd3l1KpdMvfp7g47e7usre3d6qM0Og0sl/jzA90OPsDHTZbd/FPJvb5gYRjp9kin8+f2umW4RvUbiQichb4knPu7X3a/gh40Tn32e7t14BHnHPf8+dqZWXFzc/P39b4+XyeM2fO3NZjtWEu+vDFA8xFE0++8AbPv14B4L3Tbb5WSgHw2L0TXHz07KmPs7a2trqwsPBgv7Y7dbrmGeBD3VU2DwPV3oAflGw2G+ThIsVc9OGLB5iLJi48MMfc+EGwv7GbAGBuPMWFB4J7yzKQ0zUi8lngEWBaRK4CHwOSAM65p4BngfPAZWAX+HAQ4x6l3W4HfcjIMBd9+OIB5qKJucwwT557G5dWNxjZr3FvMhP46ppAQt4594ET2h2wHMRYx9FsNsM8/B3FXPThiweYizbmMsNcfPRsaKeevPnEqw/rZW9gLvrwxQPMRSthuXgT8nFfL3sUc9GHLx5gLloJy8WbkE+lUlGXEBjmog9fPMBctBKWizchPz4+HnUJgWEu+vDFA8xFK2G5eBPy5XI56hICw1z04YsHmItWwnLxJuQnJiaiLiEwzEUfvniAuWglLBdvQt6HpVQ3MBd9+OIB5qKVsFy8CflWqxV1CYFhLvrwxQPMRSthuXgT8rZeVie+uPjiAeaiFVsnfwK2XlYnvrj44gHmohVbJ38CIyMjUZcQGOaiD188wFy0EpaLNyGfTqejLiEwzEUfvniAuWglLBdvQr5SqURdQmCYiz588QBz0UpYLt6E/NTUVNQlBIa56MMXDzAXrYTl4k3I1+v1qEsIDHPRhy8eYC5aCcvFm5CP++YBRzEXffjiAeailbBcAgl5EXmfiLwmIpdF5GKf9kdEpCoiL3UvHw1i3KPYelmd+OLiiweYi1bUrpMXkQTwh8A54H7gAyJyf5+uf+Wce0f38juDjtuLrZfViS8uvniAuWhF8zr5h4DLzrnvOufawOeAxwM47veFLaXSiS8uvniAuWglLJcg9ni9B7hy5PZV4F19+r1bRL4FrAO/6px7pbfD1tYWS0tLDA0N0el0WFxcZHl5mUKhwOjoKIlEglqtRi6XY3t7G+ccuVyOzc1NRIRyuUyj0WBmZoZisYiIMDk5SbFYJJPJ0Ol02NnZYXZ2lkKhQDKZJJvNUiqVyGaztNttms3mYXsqlWJ8fJxyuczExATNZpNWq3XYPjIyQjqdplKpMDU1Rb1ep91uH7an02lSqRTVapXp6Wmq1Sr7+/uH7cc5DQ8Pk8/nGRsbA4i1U61WY29v73Ce4uq0t7dHPp/v+7MXN6dKpcJdd911y9+nuDjV63Wy2eypMkK70/DwMOvr66fKiF6nWyEHe2zfPiLys8BPO+d+rnv7g8BDzrlfOtInA1x3zjVE5Dzwcefcfb3HWllZcfPz87dVR1ib4EaBuejDFw8wF60M4rK2tra6sLDwYL+2IE7XXAXeeuT2Wzh4tn6Ic67mnGt0rz8LJEVkOoCxD5meDvRwkWIu+vDFA8xFK2G5BBHyfwvcJyI/IiIp4AngmaMdRGRWRKR7/aHuuIFug1KtVoM8XKSYiz588QBz0UpYLgOfk3fOXRORXwS+DCSAzzjnXhGRj3TbnwLeD/yCiFwDmsATbtDzRD3s7+8HebhIMRd9+OIB5qKVsFyCeOP1ximYZ3vue+rI9U8CnwxirOOw9bI68cXFFw8wF62oXSevBVsvqxNfXHzxAHPRiuZ18ioYHR2NuoTAMBd9+OIB5qKVsFy8CflEIhF1CYFhLvrwxQPMRSthuXgT8rVaLeoSAsNc9OGLB5iLVsJy8Sbkc7lc1CUEhrnowxcPMBethOXiTchvb29HXUJgmIs+fPEAc9FKWC7ehHzAy+4jxVz04YsHmItWwnLxJuTtZZtOfHHxxQPMRSt2uuYENjc3oy4hMMxFH754gLloJSwXb0L+NF+5GRfMRR++eIC5aCUsF29C3jAMw7gZb0K+0WhEXUJgmIs+fPEAc9FKWC7ehPzMzEzUJQSGuejDFw8wF62E5eJNyBeLxahLCAxz0YcvHmAuWgnLxZuQ7+5J4gXmog9fPMBctBKWSyAhLyLvE5HXROSyiFzs0y4i8olu+7dF5J1BjHuUycnJoA8ZGeaiD188wFy0EpbLwCEvIgngD4FzwP3AB0Tk/p5u54D7upefBz416Li92Ms2nfji4osHmItWNJ+ueQi47Jz7rnOuDXwOeLynz+PA0+6AbwB3i8hcAGMfkslkgjxcpJiLPnzxAHPRSlguQYT8PcCVI7evdu/7fvsMRKfTCfJwkWIu+vDFA8xFK2G5BLHHa793C3q/aec0fdja2mJpaYmhoSE6nQ6Li4ssLy9TKBQYHR0lkUhQq9XI5XJsb2/jnCOXy7G5uUmz2UREaDQazMzMUCwWEREmJycpFotkMhk6nQ47OzvMzs5SKBRIJpNks1lKpRLZbJZ2u02z2TxsT6VSjI+PUy6XmZiYoNls0mq1DttHRkZIp9NUKhWmpqao1+u02+3D9nQ6TSqVolqtMj09TbVaZX9//7D9OKd2u83Ozs7hJ+Di7LSxsUGz2Tycp7g6lUoldnZ2+v7sxc1pfX0d4Ja/T3FxKpVKjI+PnyojtDu1223a7fapMqLX6ZYBPeg3n4nIu4Hfcs79dPf2rwM4537vSJ8/Al50zn22e/s14BHn3MbRY62srLj5+fnbqmNvb4/h4eHbk1CGuejDFw8wF60M4rK2tra6sLDwYL+2IE7X/C1wn4j8iIikgCeAZ3r6PAN8qLvK5mGg2hvwg2Ib+urEFxdfPMBctBKWy8Cna5xz10TkF4EvAwngM865V0TkI932p4BngfPAZWAX+PCg4/aSTCaDPmRkmIs+fPEAc9FKWC5BnJPHOfcsB0F+9L6njlx3wHIQYx1HNpsN8/B3FHPRhy8eYC5aCcvFm0+8lkqlqEsIDHPRhy8eYC5aCcvFm5C3v+g68cXFFw8wF63YM/kTaLfbUZcQGOaiD188wFy0EpaLNyHfbDajLiEwzEUfvniAuWglLBdvQn52djbqEgLDXPThiweYi1bCcvEm5G29rE58cfHFA8xFK2G5eBPyqVQq6hICw1z04YsHmItWwnLxJuTHx8ejLiEwzEUfvniAuWglLBdvQr5cLkddQmCYiz588QBz0UpYLt6E/MTERNQlBIa56MMXDzAXrYTl4k3I21Iqnfji4osHmItWbAnlCbRarahLCAxz0YcvHmAuWgnLxZuQt/WyOvHFxRcPMBet2Dr5E7D1sjrxxcUXDzAXrdg6+RMYGRmJuoTAMBd9+OIB5qKVsFy8Cfl0Oh11CYFhLvrwxQPMRSthuQwU8iIyKSJfEZF/6P7bdw2QiLwhIt8RkZdE5O8GGfM4KpVKGIeNBHPRhy8eYC5aCctl0GfyF4GvOufuA77avX0cjzrn3uGc67vZ7KBMTU2FcdhIMBd9+OIB5qKVsFwGDfnHgUvd65eAfzXg8W6ber0e1dCBYy768MUDzEUrYbkMGvIzzrkNgO6/P3hMPwf8TxFZFZGfH3DMvtjmATrxxcUXDzAXrYTlcuJG3iLyl0C/BZy/+X2M8x7n3LqI/CDwFRH5e+fc13s7bW1tsbS0xNDQEJ1Oh8XFRZaXlykUCoyOjpJIJKjVauRyOba3t3HOkcvl2NzcZGRkhHK5TKPRYGZmhmKxiIgwOTlJsVgkk8nQ6XTY2dlhdnaWQqFAMpkkm81SKpXIZrO0222azeZheyqVYnx8nHK5zMTEBM1mk1arddg+MjJCOp2mUqkwNTVFvV6n3W4ftqfTaVKpFNVqlenpaarVKvv7+4ftxzlNTEyQz+cZGxsDiLUTwJUrVw7nKa5O6XSafD7f92cvbk6dTodSqXTL36e4OHU6Hfb29k6VEdqdMpkM6+vrp8qIXqdbZrhz7vvI6p4Hi7wGPOKc2xCROeBF59w/OuExvwU0nHO/39u2srLi5ufnb6uWfD7PmTNnbuux2jAXffjiAeailUFc1tbWVhcWFvq+3zno6ZpngAvd6xeAP+/tICKjIjJ+4zrwz4GXBxz3JmwplU58cfHFA8xFKyqXUAJPAj8lIv8A/FT3NiLyQyLybLfPDPDXIvIt4G+Av3DO/Y8Bx70J2zxAJ764+OIB5qKVsFxOPCd/K5xzZWChz/3rwPnu9e8CPz7IOKehWq1y9913hz3MHcFc9OGLB5iLVsJy8eYTr9PT01GXEBjmog9fPMBctBKWizchX61Woy4hMMxFH754gLloJSwXb0J+f38/6hICw1z04YsHmItWwnLxJuTte6V14ouLLx5gLlqx75M/AfteaZ344uKLB5iLVuz75E9gdHQ06hICw1z04YsHmItWwnLxJuQTiUTUJQSGuejDFw8wF62E5eJNyNdqtahLCAxz0YcvHmAuWgnLxZuQv/FlWD5gLvrwxQPMRSthuXgT8tvb21GXEBjmog9fPMBctBKWizchP8i3aWrDXPThiweYi1bCcvEm5O1lm058cfHFA8xFK3a65gQ2NzejLiEwzEUfvniAuWglLBdvQv40O6TEBXPRhy8eYC5aCcvFm5A3DMMwbsabkG80GlGXEBjmog9fPMBctBKWy0AhLyI/KyKviMh1Eem7v2C33/tE5DURuSwiFwcZ8zhmZmbCOGwk+OCyUdvjyRfe4NOvNHnyhTfYqO1FXdJA+DAnNzAXnYTlMugz+ZeBReDrx3UQkQTwh8A54H7gAyJy/4Dj3kSxWAz6kJERd5eN2h4Xn7vM869XGNqr8vzrFS4+dznWQR/3OTmKuegkLJeBQt4596pz7rUTuj0EXHbOfdc51wY+Bzw+yLj9EJGgDxkZcXe5tLrBRr0NwDV34LJRb3NpdSPKsgYi7nNyFHPRSVguA+3xekruAa4cuX0VeFe/jltbWywtLTE0NESn02FxcZHl5WUKhQKjo6MkEglqtRq5XI7t7W2cc+RyOTY3N0kmk5TLZRqNBjMzMxSLRUSEyclJisUimUyGTqfDzs4Os7OzFAoFkskk2WyWUqlENpul3W7TbDYP21OpFOPj45TLZSYmJmg2m7RarcP2kZER0uk0lUqFqakp6vU67Xb7sD2dTpNKpahWq0xPT1OtVtnf3z9sP85pbGyMfD5/+G573Jzuajd473Sbl2tDjCau80+n2nynNsR0p0K5PB5Lp6GhIfL5fN+fvbjNU6vVolQq3fL3KS5OrVaLvb29U2WEdqexsTHW19dPlRG9TrdCTvqUlYj8JdDv2+x/0zn3590+LwK/6pz7uz6P/1ngp51zP9e9/UHgIefcL/X2XVlZcfPz8ycW3Y98Ps+ZM2du67HaiLvLky+8wfOvVwB473Sbr5UOdqF/7N4JLj56NsLKbp+4z8lRzEUng7isra2tLiws9H1f9MRn8s65n7ytUf8/V4G3Hrn9FmB9wGPeRCaTCfqQkRF3lwsPzPHq1g4b9TZXmwdnBOfGU1x4YC7iym6fuM/JUcxFJ2G53InTNX8L3CciPwL8X+AJ4N8GPUin0wn6kJERd5e5zDBPnnsbl1Y3SLXrnJkd58IDc8xlhqMu7baJ+5wcxVx0EpbLoEso/7WIXAXeDfyFiHy5e/8PicizAM65a8AvAl8GXgU+75x7ZbCyb2ZnZyfoQ0aGDy5zmWEuPnqWfzOf4eKjZ2Md8ODHnNzAXHQSlstAz+Sdc38G/Fmf+9eB80duPws8O8hYJ2Eb+urEFxdfPMBctGIbeZ+AbeirE19cfPEAc9GKbeR9Al/84hejLiEwzEUfvniAuWglLBdvQv4LX/hC1CUEhrnowxcPMBethOXiTchfu3Yt6hICw1z04YsHmItWwnI58cNQd5KvfvWrRSB/O4/d3t6enpycLAVcUiSYiz588QBz0cqALmcWFhb6bi2lKuQNwzCMYPHmdI1hGIZxMxbyhmEYHhOrkBeRz4jIloi8fEy7iMgnupuTfFtE3nmnazwtp3B5RESqIvJS9/LRO13jaRCRt4rICyLyancDmV/u0ycW83JKl7jMy4iI/I2IfKvr8tt9+sRlXk7jEot5gYM9NkTkf4nIl/q0BT8nzrnYXIB/BrwTePmY9vPAc4AADwPfjLrmAVweAb4UdZ2n8JgD3tm9Pg78H+D+OM7LKV3iMi8CjHWvJ4FvAg/HdF5O4xKLeenW+h+B/96v3jDmJFbP5J1zXwe2b9HlceBpd8A3gLtFROVXH57CJRY45zacc2vd63UOvp/onp5usZiXU7rEgu7/9Y1NQ5PdS+8qi7jMy2lcYoGIvAX4F8B/PaZL4HMSq5A/Bf02KInlL2mXd3dfoj4nIj8WdTEnISJngZ/g4JnWUWI3L7dwgZjMS/e0wEvAFvAV51xs5+UULhCPeflPwK8B149pD3xOfAv5fvtnxfIvPrAGnHHO/Tjwn4EvRlvOrRGRMeBPgf/gnKv1Nvd5iNp5OcElNvPinOs4597BwR4OD4nI23u6xGZeTuGifl5E5GeALefc6q269blvoDnxLeTvyAYldwLnXO3GS1R38C2eSRGZjrisvohIkoNQ/BPnXL/PZsdmXk5yidO83MA59ybwIvC+nqbYzMsNjnOJyby8B/iXIvIGB3tdPyYi/62nT+Bz4lvIPwN8qPsO9cNA1TkXy92jRWRW5GBnXxF5iIO5Kkdb1c10a/w08Kpz7g+O6RaLeTmNS4zmJScid3evp4GfBP6+p1tc5uVElzjMi3Pu151zb3HOneVg86TnnXP/rqdb4HNyJ3aGCgwR+SwH76JPy8FmJR/j4E0YnHNPcfCd9eeBy8Au8OFoKj2ZU7i8H/gFEbkGNIEnXPftd2W8B/gg8J3uOVOA3wB+GGI3L6dxicu8zAGXRCTBQeB93jn3JRH5CMRuXk7jEpd5uYmw58S+1sAwDMNjfDtdYxiGYRzBQt4wDMNjLOQNwzA8xkLeMAzDYyzkDcMwPMZC3jAMw2Ms5A3DMDzGQt4wDMNj/h/YeFrpI2++RQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 2]\n",
      " [1 3]\n",
      " [1 4]]\n"
     ]
    }
   ],
   "source": [
    "A = np.hstack([x**i for i in range(2)])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{bmatrix} 1 & 1\\\\ 1 & 2 \\\\ 1 & 3\\\\ 1 & 4 \\end{bmatrix} \\begin{bmatrix} x \\\\ y\\\\ \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ -1 \\\\ 2 \\\\ 1 \\end{bmatrix} $$\n",
    "\n",
    "$$\\begin{cases} x+y &= 3\\\\ x +2y &= -1 \\\\ x+ 3y &=2 \\\\x + 4y &= 1 \\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution matches with the one we obtain by visually inspecting the least squares surface and contour plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residual is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the squared error is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that like our previous work on optimal representation using squared error, the residual also satisfies the orthogonality principal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The residual is orthogonal to the columns of $\\mathbf{A}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ```Numpy``` Implementation\n",
    "\n",
    "Let's start by using ```numpy``` functions to implement the least squares solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a square system now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = np.linspace(-0.2,4.2, 100)\n",
    "\n",
    "# Estimate the polynomial model\n",
    "y2 = \n",
    "\n",
    "plt.scatter(x,y,label='Data points')\n",
    "plt.plot(xl, y2,'r',label='Polynomial Model')\n",
    "plt.legend(loc='center left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the polynomial model\n",
    "y3 = \n",
    "\n",
    "plt.scatter(x,y,label='Data points')\n",
    "plt.plot(xl, y3,'r',label='Polynomial Model')\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the case of wide matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3]]).T\n",
    "\n",
    "y = np.array([[3,-1,2]]).T\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estiamte the polynomial model\n",
    "y_prediction = \n",
    "\n",
    "plt.scatter(x,y,label='Data points')\n",
    "plt.plot(xl, y_prediction,'r',label='Polynomial Model')\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "    <b>Linear Regression</b>\n",
    "    \n",
    "One approach to solve the problem where we are dealing with an *inconsistent* and *over-determined* system of linear equations is to find the *solution* that **minimizes the least squares error**. This solution is known as **linear regression**.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use linear regression from two approaches:\n",
    "\n",
    "1. By transforming the output variable (or desired response) -- we saw examples of this when we first transformed the COVID-19 data to log-space and then applied the linear regression\n",
    "\n",
    "2. By transforming the input variable (or data samples) -- e.g. linear regression of samples polynomial representations (polynomial regression)\n",
    "\n",
    "and then *fitting the curve* on either of these transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose our data comes from a noisy sinusoidal: $t = \\sin(2\\pi x) + \\epsilon$ where $\\epsilon$ is a (univariate) Gaussian zero-mean random noise. \n",
    "\n",
    "* The input samples are $x$\n",
    "* The desired values are $t + \\epsilon$, but we know that $t = \\sin(2\\pi x)$\n",
    "* Our **goal** is to find a model that fits the set of data samples $\\{x_i,t_i\\}_{i=1}^N$\n",
    "* We also want our model to be able to correctly **predict** the desired value of a new data sample $x_{test}$\n",
    "\n",
    "Let's generate data from the *true* underlying function, $t=\\sin(2\\pi x)$, which, in practice, we would not know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NoisySinusoidalData(N, a, b, gVar):\n",
    "    x = np.linspace(a,b,N)\n",
    "    noise = npr.normal(0,gVar,N)\n",
    "    t = np.sin(2*np.pi*x) + noise\n",
    "    return x[:,np.newaxis], t[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 150\n",
    "Ntest = 50 \n",
    "a, b = [0,1] \n",
    "gVar_train = 0.5\n",
    "gVar_test = 0.8\n",
    "xtrain, ytrain = NoisySinusoidalData(N, a, b, gVar_train)    # training data and labels\n",
    "xtrue, ytrue = NoisySinusoidalData(N, a, b, 0)             #true sine function\n",
    "xtest, ytest = NoisySinusoidalData(Ntest, a, b, gVar_test) # test data and labels\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(xtrain, ytrain, 'bo', label = 'Training Data')\n",
    "plt.plot(xtrue, ytrue, 'g', linewidth=4, label = 'True Sinusoidal')\n",
    "plt.plot(xtest, ytest, 'r*', label = 'Test Data')\n",
    "plt.legend()\n",
    "plt.xlabel('Data Samples, x', fontsize=15)\n",
    "plt.ylabel('Desired Values, t', fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Polynomial_Regression(x,b,M):\n",
    "    '''This function implements Linear Regression with polynomial representation\n",
    "    of order M for input variable x and right-hand-sides vector b'''\n",
    "    \n",
    "    # Polynomial representations -- Linear Transformation A\n",
    "    \n",
    "    \n",
    "    # Coefficients\n",
    "    \n",
    "    \n",
    "    # Prediction\n",
    "    \n",
    "    \n",
    "    # Residual\n",
    "    \n",
    "    \n",
    "    # Mean-Squared Error\n",
    "    \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = ### define polynomial model order\n",
    "\n",
    "A, c, ytrain_pred, r, MSE = Polynomial_Regression(xtrain, ytrain, M) \n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(xtrain,ytrain_pred,'c', label = 'Estimated Polynomial', linewidth=5)\n",
    "plt.plot(xtrue,ytrue,'g', label = 'True Function', linewidth=5)\n",
    "plt.plot(xtrain,ytrain,'bo', label='Training Data')\n",
    "plt.legend()\n",
    "plt.xlabel('Data Samples, x', fontsize=15)\n",
    "plt.ylabel('Desired Values, t', fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.stem(c)\n",
    "plt.ylabel('Weight values', size=15)\n",
    "plt.xticks(np.arange(len(c)), ['$c_{'+str(i)+'}$' for i in range(len(c))],rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Polynomial_Regression_test(x,c):\n",
    "    '''This function evaluates the performance of Polynomial Regression with\n",
    "    coefficients c and test set x'''\n",
    "    \n",
    "    # Polynomial representations -- Linear Transformation A for test data\n",
    "    \n",
    "    \n",
    "    # Prediction using the trained/learned coefficients\n",
    "    \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict model for the test data xtest using the function above and solution for the coefficients c\n",
    "_, ytest_pred = Polynomial_Regression_test(xtest, c)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(xtrain,ytrain_pred,'c', label = 'Estimated Polynomial',linewidth=4)\n",
    "plt.plot(xtrue,ytrue,'g', label = 'True Function',linewidth=4)\n",
    "plt.plot(xtest,ytest,'ro', label = 'Test Data')\n",
    "plt.plot(xtest,ytest_pred,'-m', label = 'Test Predictions', linewidth=4)\n",
    "plt.legend()\n",
    "plt.xlabel('Data Samples, x', fontsize=15)\n",
    "plt.ylabel('Desired Values, t', fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
