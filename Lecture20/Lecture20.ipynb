{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 20\n",
    "- Introduction to Vectors & Vector Operations\n",
    "- Introduction to Matrices\n",
    "- Correlations\n",
    "- Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Introduction to vectors\n",
    "- Vector addition\n",
    "- Vector scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong>Dimension</strong>\n",
    "    \n",
    "The **dimension** (or **size**) of a vector is the number of elements it contains.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Special vectors\n",
    "\n",
    "**<font color=\"blue\">Zero Vectors</font>** A *zero vector* is a vector with all elements equal to zero. We will denote the $n$-dimensional zero vector by $\\mathbf{0}_n$.\n",
    "\n",
    "$~~~~~$ For example, \n",
    "\\begin{align}\n",
    "\\mathbf{0}_5 = \n",
    "\\begin{bmatrix}\n",
    "0\\\\0\\\\0\\\\0\\\\ 0\n",
    "\\end{bmatrix}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<font color=\"blue\">Ones vectors</font>** A *ones vector* is a vector with all elements equal to one. We will denote the $n$-dimensional ones vector by $\\mathbf{1}_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**<font color=\"blue\">Standard Unit Vectors</font>** A *standard unit vector* is a vector with all elements equal to zero, except one element which is equal to one. \n",
    "\n",
    "For a given dimension $n$, we denote the stanard unit vector with element $i$ equal to 1 by $e_i$. \n",
    "\n",
    "For example, the three standard unit vectors of dimension 3 are:\n",
    "\n",
    "\\begin{align}\n",
    "e_1=\n",
    "\\begin{bmatrix}\n",
    "1\\\\ 0\\\\ 0\n",
    "\\end{bmatrix}, ~~~~~\n",
    "e_2=\n",
    "\\begin{bmatrix}\n",
    "0\\\\ 1\\\\ 0\n",
    "\\end{bmatrix}, ~~~~~\n",
    "e_3=\n",
    "\\begin{bmatrix}\n",
    "0\\\\ 0\\\\ 1\n",
    "\\end{bmatrix}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Properties of Vector Addition\n",
    "\n",
    "Because vector addition is component-wise scalar addition, it inherits many of its properties from scalar addition.\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "* *Commutative*: $\\mathbf{a}+\\mathbf{b} = \\mathbf{b} + \\mathbf{a}$\n",
    "* *Associative*: $(\\mathbf{a}+\\mathbf{b}) +\\mathbf{c} = \\mathbf{a}+(\\mathbf{b} +\\mathbf{c})$\n",
    "* *Identity*: The zero-vector is the identity for vector addition: $\\mathbf{a} + \\mathbf{0}  = \\mathbf{a}$\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Properties of Scaling\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "\n",
    "* *Commutative*: $\\alpha \\mathbf{x} = \\mathbf{x} \\alpha$\n",
    "* *Associative*: If $\\alpha$ and $\\beta$ are scalars, then $(\\alpha  \\beta) \\mathbf{x} = \\alpha (\\beta \\mathbf{x})$\n",
    "* *Distributive over scalar addition*: $(\\alpha+\\beta) \\mathbf{x} = \\alpha \\mathbf{x} + \\beta \\mathbf{x}$ and $\\mathbf{x} (\\alpha+\\beta)  = \\mathbf{x}\\alpha  + \\mathbf{x} \\beta $ \n",
    "* *Distributive over vector addition*: $\\alpha ( \\mathbf{x} +\\mathbf{y}) = \\alpha \\mathbf{x} + \\alpha \\mathbf{y}$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Today's Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inner Product of vectors\n",
    "- Introduction to Matrices\n",
    "- Moments of Matrices\n",
    "- Correlations\n",
    "- Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plotvec(*argv):\n",
    "    colors=['b','k','r','g','c','m']\n",
    "    xmin=0\n",
    "    xmax=-1000000\n",
    "    ymin=0\n",
    "    ymax=-1000000\n",
    "    origin=[0,0]\n",
    "    plt.figure()\n",
    "    for e in enumerate(argv):\n",
    "        i=e[0]\n",
    "        arg=e[1]\n",
    "        plt.quiver(*origin,*arg,angles='xy',scale_units='xy',scale=1,\n",
    "                   color=colors[i%len(colors)])\n",
    "        xmin=min(xmin,arg[0])\n",
    "        xmax=max(xmax,arg[0])\n",
    "        ymin=min(ymin,arg[1])\n",
    "        ymax=max(ymax,arg[1])\n",
    "    plt.xlim(min(-1, xmin-1), max(1,xmax+1))\n",
    "    plt.ylim(min(-1,ymin-1),max(1,ymax+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "a=[2,3]\n",
    "b=[1,-2]\n",
    "c=[-1,1]\n",
    "plotvec(a,b,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vector-Vector Multiplication: Inner Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We also can define multiplication between vectors, but that can be done in different ways. Let's start with the easiest and most common:\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong>Inner Product</strong>\n",
    "\n",
    "The *inner product* or *dot product* between two $n$-vectors $a$ and $b$ is the **scalar value** given by\n",
    "\n",
    "$$ \\mathbf{a} \\cdot \\mathbf{b} = \\mathbf{a}^T \\mathbf{b} = a_1 b_1 + a_2 b_2 + \\ldots + a_n b_n $$\n",
    "</div>\n",
    "\n",
    "I.e., multiplication is carried out elementwise, and then the resulting values are added.\n",
    "\n",
    "Inner product can also be denoted using other notation, such as $\\langle a, b\\rangle$ or $(a,b)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Write a function to compute the inner product of two vectors. Here is a \"Pythonic\" way to iterate over the corresponding elements of two vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def inner(a,b):\n",
    "    \n",
    "    \n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Use your function to compute the inner product of $\\mathbf{a}$ and $\\mathbf{b}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Use your function to compute the inner product of $[-1,2,2]^T$ and $[1,0,-3]^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we switch the order of the arguments in the inner product?\n",
    "\n",
    "Use your function to verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Properties of Inner Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "* *Commutative*: $\\mathbf{a}^T \\mathbf{b} = \\mathbf{b}^T \\mathbf{a}$\n",
    "* *Associative with scalar multiplication*: $(\\gamma \\mathbf{a})^T \\mathbf{b} = \\gamma (\\mathbf{a}^T \\mathbf{b} )$\n",
    "* *Distributive across vector addition*: $(\\mathbf{a} +\\mathbf{b})^T \\mathbf{c} = \\mathbf{a}^T \\mathbf{c} +\\mathbf{b}^T \\mathbf{c}$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Special examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Inner product with Standard Unit Vector**\n",
    "\n",
    "$\\mathbf{e}_i^T \\mathbf{a} = a_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Computing the inner product with the $i$th standard unit vector returns the $i$th element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Inner product with 1s vector: Summation**\n",
    "\n",
    "$\\mathbf{1}^T \\mathbf{a} = a_1 + a_2 + \\ldots + a_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Averaging** \n",
    "\n",
    "$\\frac{1}{n} \\mathbf{1}^T \\mathbf{a} = [1/n, 1/n, \\ldots, 1/n]^T \\mathbf{a} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Sum of Squares**\n",
    "\n",
    "$ \\mathbf{a}^T\\mathbf{a} = a_1^2 + a_2^2 + \\cdots + a_n^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Lengths of Vectors**\n",
    "\n",
    "For vectors $a$ and $b$, what are their lengths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We denote the length of a vector $\\mathbf{a}$ by $\\| \\mathbf{a}\\|$, which is read **norm** of $ \\mathbf{a}$. Thus,\n",
    "\n",
    "$$ \\|\\mathbf{a}\\|^2 = \\mathbf{a}^T\\mathbf{a} $$\n",
    "\n",
    "The inner-product of a vector with itself is its norm-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Orthogonal vectors**\n",
    "\n",
    "Consider the two standard unit vectors and their inner product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider, $a=[2,1]$ and $b=[-1, 2]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if the inner product of two vectors is zero, then the vector are perpendicular, that is, they have an 45$^\\circ$ angle between them. This is a sufficient and necessary condition, that is:\n",
    "\n",
    "$$\\mathbf{x}^T\\mathbf{y} = 0 \\iff \\mathbf{x} \\perp \\mathbf{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Operations\n",
    "\n",
    "1. **Vector Summation**: if $\\mathbf{c}= \\mathbf{a} + \\mathbf{b}$, then \n",
    "\n",
    "\\begin{align*}\n",
    "c_i = a_i+b_i\n",
    "\\end{align*}\n",
    "\n",
    "for all $i=1,2,\\ldots,n$. \n",
    "\n",
    "2. **Scalar-Vector Multiplication** or **scaling**: in scalar-vector multiplcation, a vector is  multiplied by a scalar (a number). This is achieved by multiplying every element of the vector by the scalar: \n",
    "\n",
    "\\begin{align*}\n",
    "\\alpha [x_1,x_2,\\dots,x_n]^T = [\\alpha x_1,\\alpha x_2,\\dots,\\alpha x_n]^T\n",
    "\\end{align*}\n",
    "\n",
    "3. **Vector-Vector Product** or **Inner Product** or **Dot Product**: The *inner product* or *dot product* between two $n$-vectors $a$ and $b$ is the **scalar value** given by \n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{a} \\cdot \\mathbf{b} = \\mathbf{a}^T \\mathbf{b} = a_1 b_1 + a_2 b_2 + \\ldots + a_n b_n\n",
    "\\end{align*}\n",
    "\n",
    "4. **Length of Vectors**: we denote the length of a vector $\\mathbf{a}$ by $\\| \\mathbf{a}\\|$, which is read **norm** of $ \\mathbf{a}$. The norm of a vector is the square-root of the inner product of a vector, that is, \n",
    "\n",
    "\\begin{align*}\n",
    "\\|\\mathbf{a}\\| = \\sqrt{\\mathbf{a}^T\\mathbf{a}}\n",
    "\\end{align*}\n",
    "\n",
    "5. **Orthogonal vectors** or **perpendicular vectors**: if the inner product of two vectors is zero, then the vectors are perpendicular, that is, they have an 90$^\\circ$ angle between them. This is a sufficient and necessary condition, that is:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{x}^T\\mathbf{y} = 0 \\iff \\mathbf{x} \\perp \\mathbf{y}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectors in ```NumPy```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw how to implement operations like vector addition, scalar-vector multiplication, and vector inner product.\n",
    "\n",
    "```NumPy``` can do all these operations on vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[2,3]\n",
    "b=[1,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a reminder, Python doesn't know you are treating these lists\n",
    "# as vectors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast these to numpy arrays:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these are row vectors! That is okay for most operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector addition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scalar multiplication\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#But be careful:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In general, operations assume elementwise operation unless you use special operators.**\n",
    "\n",
    "There are 2 common ways to do the inner/dot product in numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second approach, the \"@\" symbol is a general symbol indicating matrix multiplication. Note that the second approach matches the inner product notation favored by Boyd:\n",
    "\n",
    "$\\mathbf{a}^T \\mathbf{b} = \\mathbf{a} \\cdot \\mathbf{b}$,\n",
    "\n",
    "whereas the first approach is the dot product notation usually used in engineering and physics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special Vectors\n",
    "\n",
    "```NumPy``` knows how to make several special vectors that we discussed in class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeros vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ones vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard indicator vector with 1 in first place\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard indicator vector with 1 in kth place. Ex: k=3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latter function arguments are confusing, but we aren't ready to explain them yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A First Glimpse at Matrices: Stacking Vectors Horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```NumPy``` knows how to stack vectors horizontally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAREFUL: hstack takes a tuple of vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened? Remember that we made **row** vectors. To make column vectors, we need to enter the values like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning a ```NumPy``` 1-D vector into a column vector is a little tricky because a 1-D vector only has one axis! We can do it by adding a new axis and then move it 90 degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call this type of 2-D table a **matrix**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix indexing\n",
    "\n",
    "We can get the values out of the array by **indexing**. Matrices are indexed like:\n",
    "\n",
    "**M**[row, column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0, 0 element (1st row, 1st col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, 0 element: (2nd row, 1st column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1,1 element:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pull out whole rows or columns by putting \":\" for the other index. In particular, to pull out the two vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First column:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second column:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First row:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that vectors do not have to contain only fixed numerical values. \n",
    "\n",
    "A vector can consist of variables $\\mathbf{x}=[x_1,x_2]^T$. This is very useful to compactly represent linear equations:\n",
    "$$\\left[1,4,-2\\right]^T \\left[x,y,z\\right] = 3$$\n",
    "is equivalent to \n",
    "$$x +4y -2z =3$$\n",
    "\n",
    "Later, we will see that this notation is even **more** useful when we are representing **systems of linear equations**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector can also have components that are random variables, such as $\\mathbf{X}=[X_1, X_2]^T$. In this case, the vector is called a **vector random variable** or **n-dimensional random variable**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture we introduce summary statistics for vectors of data and moments for vector random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averages and Means, Medians\n",
    "\n",
    "The average of set of $n$-vectors is vector of the averages of the components:\n",
    "\n",
    "$\\overline{\\mathbf{x}} = \\left[ \\overline{x_1}, \\overline{x_2}, \\ldots, \\overline{x_n} \\right]^T$\n",
    "\n",
    "Let's look at the vector average for the Firearms dataset on Number of State Gun Laws vs Firearms Mortality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('firearms-combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(##,##)\n",
    "plt.xlabel('Total Gun Laws in a State in 2014')\n",
    "plt.ylabel('Firearms Mortality Rate in 2014');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(##,##)\n",
    "plt.xlabel('Total Gun Laws in a State in 2014')\n",
    "plt.ylabel('Firearms Mortality Rate in 2014');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we see that $\\mathbf{x}$ has our data. But what is $\\mathbf{x}$ like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of $\\mathbf{x}$ corresponds to data from one state. For instance, let's look at row 8, which corresponds to FL: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this means 21 total laws and 11.5 firearms mortality rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we are asked to find the average of this data, we are finding the average of each component: in other words, we are finding the average of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that just calling average on $\\mathbf{x}$ doesn't do what we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can be more concise and get our desired result if we tell ```NumPy``` to average over the data in rows (axis=0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the median of a set of vectors is the vector of the medians of the components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Total Laws 2014'],df['RATE-2014'])\n",
    "plt.xlabel('Total Gun Laws in a State in 2014')\n",
    "plt.ylabel('Firearms Mortality Rate in 2014');\n",
    "\n",
    "mean = ##\n",
    "median = ##\n",
    "plt.scatter(##, color='red', marker='X', s=100, label='Average')\n",
    "plt.scatter(##, color='green', marker='X', s=100, label='Median')\n",
    "plt.legend(fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Means of Random Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong>Means of Random Vectors</strong>\n",
    "    \n",
    "For a vector random variable $\\mathbf{X}=[X_1, X_2]^T$, the **mean vector** is the vector of component means:\n",
    "\n",
    "\\begin{align} \n",
    "E[\\mathbf{X}] & = E\\bigl[\\left[X_1, X_2\\right]^T \\bigr]\\\\ \n",
    "& = \\bigl[E\\left[X_1\\right], E\\left[X_2\\right] \\bigr]^T\n",
    "\\end{align}\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher-order Moments: Variances, Covariances, and Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the variance of a random variable is the 2nd central moment:\n",
    "$$\n",
    "\\operatorname{Var}(Y) = E \\left[ \\left(Y - \\mu_Y\\right)^2 \\right]\n",
    "$$\n",
    "\n",
    "It is a measure of the \"spread\" of probability density away from the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ```NumPy``` to compute the variance of a data set.\n",
    "\n",
    "* Remember that we should always use the **unbiased estimator** for the variance: $s^2_{n-1}=\\frac{1}{n-1} \\sum_{i=1}^{n} \\left(y_i - \\overline{y}\\right)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(##)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we need to specify which entries we want to compute the variance for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(##)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong>Variance of Random Vectors</strong>\n",
    "    \n",
    "The variance of a vector random variable is defined as the vector of variances of the components:\n",
    "\n",
    "$$ \\operatorname{Var}\\left(\\mathbf{X} \\right) = \\bigl[ \\operatorname{Var}\\left[X_1\\right], \\operatorname{Var}\\left[X_2\\right], \\ldots, \\operatorname{Var}\\left[X_n\\right] \\bigr]^T $$\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More commonly, we measure not only the spread of each individual random variable in a vector but also the way that the probability of the different random variables are spread with respect to each other:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong>Covariance</strong>\n",
    "\n",
    "The **covariance** of two random variables $X$ and $Y$, denoted by $\\text{cov}(X,Y)$, is defined by\n",
    "\n",
    "$$\\text{cov}(X,Y) = E\\bigl[\\left(X-E\\left[X\\right]\\right) \\left(Y-E\\left[Y\\right]\\right)\\bigr]$$\n",
    "    \n",
    "</div>\n",
    "\n",
    "Note that \n",
    "$$ \\operatorname{Var}(X)= \\operatorname{Cov}(X,X) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Roughly speaking, a positive or negative covariance indicates that the values of $X-E[X]$ and $Y-E[Y]$ obtained in a single experiment \"tend\" to have the same or opposite sign, respectively.\n",
    "\n",
    "* Thus, the sign of the covariance provides an important *qualitative* indicator of the relationship between $X$ and $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing covariance for random variables requires understanding *joint probability distributions* -- this topic is outside the scope of this class.\n",
    "\n",
    "However, we will compute the covariance when we are working with vectors of data\n",
    "\n",
    "If $\\{x_i\\}$ and $\\{y_i\\}$ are sample data from some random variables $X$ and $Y$, then the unbiased (sample) covariance is \n",
    "$$\n",
    "\\frac{1}{n-1} \\sum_{i=1}^{n} \\left(x_i - \\overline{x}\\right)\n",
    "\\left(y_i - \\overline{y}\\right) \n",
    "$$\n",
    "\n",
    "Fortunately (but somewhat inconsistently), ```NumPy``` uses the unbiased estimator for covariance by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's check the variances of our gun-law data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(##), np.cov(##)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(##), np.cov(##)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can get all the variances and covariances of our data as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(##)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if our vectors are not already stacked into an array, we can still compute the covariances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(##)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called a **Covariance Matrix**. It is a table of the variances and covariances of the data in the following form \n",
    "\\begin{align}\n",
    "\\mathbf{K_X} &= \n",
    "\\begin{bmatrix}\n",
    "\\operatorname{Cov}(\\mathbf{X}_1, \\mathbf{X}_1) & \\operatorname{Cov}(\\mathbf{X}_1, \\mathbf{X}_2)  \\\\\n",
    "\\operatorname{Cov}(\\mathbf{X}_2, \\mathbf{X}_1) & \\operatorname{Cov}(\\mathbf{X}_2, \\mathbf{X}_2)  \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "&\\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "\\operatorname{Var}(\\mathbf{X}_1) & \\operatorname{Cov}(\\mathbf{X}_1, \\mathbf{X}_2)  \\\\\n",
    "\\operatorname{Cov}(\\mathbf{X}_1, \\mathbf{X}_2) & \\operatorname{Var}(\\mathbf{X}_2)  \\\\\n",
    "\\end{bmatrix} \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the covariance is negative for these two data samples. This generally implies that when one goes up, the other goes down. Let's look at the data again to see whether this holds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Total Laws 2014'],df['RATE-2014'])\n",
    "plt.xlabel('Total Gun Laws in a State in 2014')\n",
    "plt.ylabel('Firearms Mortality Rate in 2014');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color=\"blue\">Another Example</font>**\n",
    "\n",
    "\"The **Behavioral Risk Factor Surveillance System (BRFSS)** is the nation's premier system of health-related telephone surveys that collect state data about U.S. residents regarding their health-related risk behaviors, chronic health conditions, and use of preventive services.\": https://www.cdc.gov/brfss/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BRFSS contains 450015 records, with over 350 variables. It takes a LONG time to load and work with, so we have pulled out 2 variables and sampled 5000 records for us to work with\n",
    "\n",
    "The data we will use is\n",
    "\n",
    "* **HEIGHT**: a new computed variable as the height in inches\n",
    "\n",
    "* **WEIGHT2**: The reported weight in pounds\n",
    "\n",
    "We dropped those entries that did not have valid values or were reported in metric units (a small percentage of the total)\n",
    "\n",
    "The resulting dataframe is stored in the pickle file ```brfss17.pickle```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file=##\n",
    "df2=##\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(##, ##)\n",
    "plt.xlabel('Height in inches')\n",
    "plt.ylabel('Weight in pounds');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should the sign of the covariance be?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(##,##)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at what happens for some independent data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=##\n",
    "Z=##\n",
    "y=##\n",
    "z=##\n",
    "plt.scatter(y,z);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the very small sample covariance. When random variables are independent, their covariance is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\{x_i\\}$ refer to the first feature (or dimension) and $\\{y_i\\}$ refer to the second feature (or dimension). Then:\n",
    "\n",
    "* If $y_i$ generally increases with $x_i$ (and vice versa), then $\\operatorname{Cov}(\\mathbf{x},\\mathbf{y}) >0$\n",
    "\n",
    "* If $y_i$ generally decreases with $x_i$ (and vice versa), then  $\\operatorname{Cov}(\\mathbf{x},\\mathbf{y}) <0$\n",
    "\n",
    "* If $x_i$ and $y_i$ are independent, then $\\operatorname{Cov}(\\mathbf{x},\\mathbf{y}) =0$\n",
    "\n",
    "So, covariance is useful in giving us some idea of how two features co-vary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it does not tell us two important things:\n",
    "1. If we want to draw through the data showing the linear dependence, what is the slope of that line? I.e., what is the general (linear) relation between the features?\n",
    "2. If we drew such a line, it does not tell us whether the data is very close to that line (meaning that we can compute one feature almost exactly from an observation of the other feature) or if the data is scattered far from that line (meaning that if we know one feature, the other feature is still pretty random)\n",
    "\n",
    "We can overcome both of these problems. We start with an observation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Suppose $X$ and $Y$ are random variables with $\\operatorname{Cov}(X,Y) \\neq 0$.\n",
    "\n",
    "* What is $\\operatorname{Cov}(aX,bY)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By linearity, $E[aX] = aE[X]$ and $E[bY]=bE[Y]$. \n",
    "\n",
    "Then \n",
    "\\begin{align*}\n",
    "\\operatorname{Cov}(aX,bY) &= E \\biggl[ \\bigl( aX - E\\left[aX\\right] \\bigr) \\bigl( bY - E\\left[bY\\right] \\bigr) \\biggr]\\\\\n",
    " &= E \\biggl[ a \\bigl( X - E\\left[X\\right] \\bigr) b \\bigl( Y - E\\left[Y\\right] \\bigr) \\biggr] \\\\\n",
    " &=ab E \\biggl[  \\bigl( X - E\\left[X\\right] \\bigr)  \\bigl( Y - E\\left[Y\\right] \\bigr) \\biggr]\\\\\n",
    " &=ab \\operatorname{Cov}(X,Y)\n",
    "\\end{align*}\n",
    "\n",
    "But if $a=b$, the relationship between the data (in terms of the slope) is really unchanged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df2['HEIGHT'], df2['WEIGHT2'])\n",
    "plt.xlabel('Height in inches')\n",
    "plt.ylabel('Weight in pounds');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(3*df2['HEIGHT'], 5*df2['WEIGHT2'])\n",
    "plt.xlabel('Height in inches')\n",
    "plt.ylabel('Weight in pounds');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's study what values $\\operatorname{cov}(\\mathbf{x},\\mathbf{y})$ can take on. \n",
    "\n",
    "Recall that the inner product of some vector $\\mathbf{a}$ with itself\n",
    "$$ \\mathbf{a}^T \\mathbf{a} = a_{1}^{2} + a_{2}^{2} + \\cdots +  a_{n}^{2} $$\n",
    "\n",
    "computes the sum of the squares of the elements. This is the square of the **length** of the vector.\n",
    "\n",
    "We can also denote the length of a vector $\\mathbf{a}$ as $\\|\\mathbf{a}\\|$, which is also read **norm of a**, and\n",
    "$$ \\text{length of }\\mathbf{a} = \\| \\mathbf{a} \\|  = \\sqrt{\\mathbf{a}^T\\mathbf{a}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cauchy-Schwarz Inequality\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong>Cauchy-Schwarz Inequality</strong>\n",
    "\n",
    "The **Cauchy-Schwarz Inequality** provides a bound on the maximum absolute value of an inner product in terms of the norms of the vectors:\n",
    "    \n",
    "$$\\left| \\langle \\mathbf{a}, \\mathbf{b} \\rangle \\right| \\le \\left\\|\\mathbf{a} \\right\\| \\left\\| \\mathbf{b}\\right\\|$$\n",
    "    \n",
    "with equality if and only if $\\mathbf{a}= c\\mathbf{b}$ for some constant $c$. \n",
    "    \n",
    "Note that $ \\langle \\mathbf{a}, \\mathbf{b} \\rangle = \\mathbf{a}^T\\mathbf{b}$ is the inner product of $\\mathbf{a}$ with $\\mathbf{b}$.\n",
    "\n",
    "*(See Boyd book, section 3.4, for proof)*\n",
    "</div>\n",
    "    \n",
    "Here, I purposefully used the general inner product notation $\\langle \\rangle$ because the Cauchy-Schwarz Inequality applies to all inner products, not just those involving vectors (e.g. inner product of matrices)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Noting our computation of covariance using inner product above, we can get\n",
    "\n",
    "\\begin{align*}\n",
    "\\left|\\operatorname{cov}(\\mathbf{x}, \\mathbf{y})  \\right|\n",
    "&= \\big\\langle \\left(\\mathbf{x} - \\boldsymbol \\mu_x \\right), \n",
    "    \\left(\\mathbf{y} - \\boldsymbol \\mu_y \\right) \\big\\rangle \\\\\n",
    "&\\le \\left\\| \\mathbf{x} - \\boldsymbol \\mu_x  \\right\\|\n",
    "    \\left\\| \\mathbf{y} - \\boldsymbol \\mu_y  \\right\\| \\\\\n",
    "&= \\sqrt{\\big\\langle \\left(\\mathbf{x} - \\boldsymbol \\mu_x \\right),\n",
    "    \\left(\\mathbf{x} - \\boldsymbol \\mu_x \\right) \\big\\rangle}\n",
    "    \\sqrt{\\big\\langle \\left(\\mathbf{y} - \\boldsymbol \\mu_y \\right),\n",
    "    \\left(\\mathbf{y} - \\boldsymbol \\mu_y \\right) \\big\\rangle} \\\\\n",
    "&= \\sqrt{\\operatorname{cov}(\\mathbf{x}, \\mathbf{x}) } \\sqrt{\\operatorname{cov}(\\mathbf{y}, \\mathbf{y}) }\\\\\n",
    "&= \\sigma_x \\sigma_y\n",
    "\\end{align*}\n",
    "\n",
    "So \n",
    "$$\\left|\\operatorname{cov}(\\mathbf{x}, \\mathbf{y})  \\right| \\leq \\sigma_x \\sigma_y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    "1. The covariance is bounded by (and depends on) the standard deviations of the data\n",
    "\n",
    "2. Equality is obtained in the bound above if and only if $\\mathbf{x} = c \\mathbf{y}$ for some $c$. The maximum possible covariance is if the features are linearly dependent; knowing one feature completely determines the other feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can use the bound to get a dependence measure that does not depend on the standard deviations of the data:\n",
    "\n",
    "\\begin{align*}\n",
    "\\left|\\operatorname{cov}(\\mathbf{x}, \\mathbf{y})\\right| &\\leq\\sigma_x \\sigma_y\\\\\n",
    "&\\\\\n",
    "\\Rightarrow \\frac{\\left|\\operatorname{cov}(\\mathbf{x}, \\mathbf{y})\\right|}{\\sigma_x \\sigma_y} &\\le 1\n",
    "\\end{align*}\n",
    "\n",
    "with equality iff $\\mathbf{x}=c\\mathbf{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# (Pearson's) Correlation Coefficient, $r$\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong>Pearson's Correlation Coefficient</strong>\n",
    "\n",
    "For random variables $X$ and $Y$, the **Pearson's correlation coefficient** (or simply the **correlation coefficient**) is\n",
    "\n",
    "\\begin{align*}\n",
    "\\rho_{XY} = \\frac{\\operatorname{cov}(X,Y)}{\\sqrt{\\text{var}(X)}\\sqrt{\\text{var}(Y)}} = \\frac{\\text{cov}(X,Y)}{\\sigma_X \\sigma_Y}\n",
    "\\end{align*}\n",
    "\n",
    "For vectors of feature data $\\mathbf{x}$ and $\\mathbf{y}$ (samples), the **(Pearson's) correlation coefficient** is \n",
    "\n",
    "\\begin{align*}\n",
    "r_{xy} = \\frac{\\hat{\\operatorname{cov}}(\\mathbf{x},\\mathbf{y})}{\\hat{\\sigma}_x \\hat{\\sigma}_y}\n",
    "\\end{align*}\n",
    "\n",
    "where $\\hat{\\operatorname{cov}}(\\mathbf{x},\\mathbf{y})$ is the sample covariance and $\\hat{\\sigma}_x$ and $\\hat{\\sigma}_y$ are the square-roots of the corresponding sample variances.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Total Laws 2014'],df['RATE-2014'])\n",
    "plt.xlabel('Total Gun Laws in a State in 2014')\n",
    "plt.ylabel('Firearms Mortality Rate in 2014');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['Total Laws 2014','RATE-2014']].to_numpy()\n",
    "\n",
    "x.shape # NxD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = ## #mean is a 2x1 vector\n",
    "\n",
    "x_median = ## # median is also 2x1 vector\n",
    "\n",
    "x_mean.shape, x_median.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['Total Laws 2014'],df['RATE-2014'])\n",
    "plt.xlabel('Total Gun Laws in a State in 2014')\n",
    "plt.ylabel('Firearms Mortality Rate in 2014')\n",
    "plt.scatter(##, ##, color='red', marker='X', s=100, label='Average')\n",
    "plt.scatter(##, ##, color='green', marker='X', s=100, label='Median')\n",
    "plt.legend(fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## # np.cov expects the matrix to be of size DxN, D is dimensionality or no. of RVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.cov(##)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Correlation Examples\n",
    "\n",
    "![Correlation Examples](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/1920px-Correlation_examples2.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Looking at these examples, correlation gives a measure of:\n",
    "* how closely the data fits a straight line\n",
    "* how much an observation of one data feature can be used to predict the other data feature\n",
    "* the correlation coefficient is only able to characterize **linear relationships** only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression -- Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To further investigate the first observation, we find the best fitting line to the data; the one that **minimizes the mean-square error**. This is called **<font color='magenta'> linear regression </font>**.\n",
    "\n",
    "We are not ready to understand the math behind linear regression yet, but we can call a function to get the best slope and y-intercept for a given data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='blue'> Example 1 </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "plt.scatter(x[:,0],x[:,1], label='Data')\n",
    "plt.scatter(x_mean[0], x_mean[1], color='red', marker='X', s=100, label='Average')\n",
    "plt.scatter(x_median[0], x_median[1], color='green', marker='X', s=100, label='Median')\n",
    "plt.xlabel('Total Gun Laws in a State in 2014')\n",
    "plt.ylabel('Firearms Mortality Rate in 2014')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='blue'> Example 2 </font>**: from the **Behavioral Risk Factor Surveillance System (BRFSS)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file=open('brfss17.pickle','rb')\n",
    "df2=pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df2['HEIGHT'], df2['WEIGHT2'])\n",
    "plt.xlabel('Height in inches')\n",
    "plt.ylabel('Weight in pounds');\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(x2, y2)\n",
    "plt.xlabel('Height in inches', fontsize=15)\n",
    "plt.ylabel('Weight in pounds', fontsize=15)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "The correlation coefficient does **not** give a measure of:\n",
    "\n",
    "1. whether the features are independent\n",
    "2. how much variance remains if we use a feature to predict the other feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coefficient of Determination, $r^2$\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong>Coefficient of Determination</strong>\n",
    "    \n",
    "The **coefficient of determination**, denoted $R^2$ or $r^2$ and pronounced \"R squared\", is the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\n",
    "\n",
    "$$r^2 = 1 - \\frac{\\text{Explained Variation}}{\\text{Total Variation}}$$\n",
    "\n",
    "and $ 0 \\leq r^2 \\leq 1$.\n",
    "\n",
    "* $r^2$ is the square of the correlation coefficient $r$.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color='red'> Correlation is not causation! </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, Video, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video('cat.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Spurious Correlations\n",
    "https://www.tylervigen.com/spurious-correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "HTML('fishing-marriage.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "HTML('spelling-spiders.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('chocolate-nobel.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Image('pets-lawyers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pets=[39.7,41.9, 44.6, 46.8, 49.8, 53.1, 56.9, 61.8, 65.7, 67.1]\n",
    "lawyers=[128553, 131139, 132452, 134468, 136571, 139371, 141030, 145355, 148399, 149982]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.linregress(pets,lawyers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Examples\n",
    "\n",
    "**Combined Cycle Power Plant Data Set** obtained from [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant).\n",
    "\n",
    "The dataset contains 9568 data samples collected from a Combined Cycle Power Plant (CCPP) over 6 years (2006-2011), when the power plant was set to work with full load. \n",
    "\n",
    "A combined cycle power plant (CCPP) is composed of gas turbines (GT), steam turbines (ST) and heat recovery steam generators. In a CCPP, the electricity is generated by gas and steam turbines, which are combined in one cycle, and is transferred from one turbine to another. While the Vacuum is collected from and has effect on the Steam Turbine, the other three of the ambient variables effect the GT performance.\n",
    "\n",
    "The *goal* is to predict the net hourly electrical energy output (PE) of the plant using a different set of features (or variables), in particular, hourly average of:\n",
    "\n",
    "* Ambient Temperature (AT),\n",
    "* Ambient Pressure (AP),\n",
    "* Relative Humidity (RH), and \n",
    "* Exhaust Vacuum (V)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('PowerPlant.csv')\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed ambient variables:\n",
    "X1 = Data['AT'].to_numpy() # hourly average Ambient Temperature (AT)\n",
    "X2 = Data['V'].to_numpy()  # hourly average Ambient Pressure (AP)\n",
    "X3 = Data['AP'].to_numpy() # hourly average Relative Humidity (RH)\n",
    "X4 = Data['RH'].to_numpy() # hourly average Exhaust Vacuum (V)\n",
    "X_all = Data[['AT','V','AP','RH']].to_numpy()\n",
    "X_labels=Data.columns[:-1]\n",
    "\n",
    "# Variable to be predicted\n",
    "Y = Data['PE'].to_numpy()  # net hourly electrical energy output (EP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ambient Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "\n",
    "plt.xlabel('Hourly average Ambient Temperature (AT)', fontsize=15)\n",
    "plt.ylabel('Net hourly electrical energy output (EP)', fontsize=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the ambient temperature information, the variance in the energy output is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the linear regression prediction, the remaining variance after the prediction is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the proportion of the original variance that is reduced by the predictor is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $r^2$ value is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ambient Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the variances before and after prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the residual variance is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient of determination is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(X3,Y)\n",
    "plt.plot(X3,Yhat3,'r')\n",
    "plt.xlabel('Hourly average Relative Humidity (RH)',fontsize=15)\n",
    "plt.ylabel('Net hourly electrical energy output (EP)',fontsize=15)\n",
    "plt.title('r = '+str(np.round(reg3[2],3))+', $r^2$ = '+str(np.round(reg3[2]**2,3)),fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining variance is not that much smaller than the original variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient of determination is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exhaust Vacuum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(X4,Y)\n",
    "plt.plot(X4,Yhat4,'r')\n",
    "plt.ylabel('Hourly average Exhaust Vacuum (V)',fontsize=15)\n",
    "plt.xlabel('Net hourly electrical energy output (EP)',fontsize=15)\n",
    "plt.title('r = '+str(np.round(reg4[2],3))+', $r^2$ = '+str(np.round(reg4[2]**2,3)),fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient of determination is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "511px",
    "left": "1555px",
    "right": "20px",
    "top": "117px",
    "width": "334px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
